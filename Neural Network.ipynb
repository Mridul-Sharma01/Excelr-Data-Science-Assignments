{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43bc569b",
   "metadata": {},
   "source": [
    "# Neutral Network(Get Turbines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32185ccd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T07:08:37.675152Z",
     "start_time": "2022-04-29T07:08:34.069238Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "273ea972",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T07:10:58.097450Z",
     "start_time": "2022-04-29T07:10:57.889399Z"
    }
   },
   "outputs": [],
   "source": [
    "get=pd.read_csv(r\"C:\\Users\\mrmri\\Downloads\\Assignments_Excelr\\Neural_Networks\\gas_turbines.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03322788",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T07:11:00.272002Z",
     "start_time": "2022-04-29T07:11:00.051949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>111.61</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>111.78</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>110.19</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>110.74</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>111.58</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  111.61  10.400   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  111.78  10.433   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  110.19  10.483   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  110.74  10.533   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  111.58  10.583   \n",
       "\n",
       "           CO     NOX  \n",
       "0      3.1547  82.722  \n",
       "1      3.2363  82.776  \n",
       "2      3.2012  82.468  \n",
       "3      3.1923  82.670  \n",
       "4      3.2484  82.311  \n",
       "...       ...     ...  \n",
       "15034  4.5186  79.559  \n",
       "15035  4.8470  79.917  \n",
       "15036  7.9632  90.912  \n",
       "15037  6.2494  93.227  \n",
       "15038  4.9816  92.498  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d5f3a18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T07:11:03.092722Z",
     "start_time": "2022-04-29T07:11:03.034709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15039 entries, 0 to 15038\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AT      15039 non-null  float64\n",
      " 1   AP      15039 non-null  float64\n",
      " 2   AH      15039 non-null  float64\n",
      " 3   AFDP    15039 non-null  float64\n",
      " 4   GTEP    15039 non-null  float64\n",
      " 5   TIT     15039 non-null  float64\n",
      " 6   TAT     15039 non-null  float64\n",
      " 7   TEY     15039 non-null  float64\n",
      " 8   CDP     15039 non-null  float64\n",
      " 9   CO      15039 non-null  float64\n",
      " 10  NOX     15039 non-null  float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "get.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "888ba50b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T07:11:04.766147Z",
     "start_time": "2022-04-29T07:11:04.337044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.00000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.764381</td>\n",
       "      <td>1013.19924</td>\n",
       "      <td>79.124174</td>\n",
       "      <td>4.200294</td>\n",
       "      <td>25.419061</td>\n",
       "      <td>1083.798770</td>\n",
       "      <td>545.396183</td>\n",
       "      <td>134.188464</td>\n",
       "      <td>12.102353</td>\n",
       "      <td>1.972499</td>\n",
       "      <td>68.190934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.574323</td>\n",
       "      <td>6.41076</td>\n",
       "      <td>13.793439</td>\n",
       "      <td>0.760197</td>\n",
       "      <td>4.173916</td>\n",
       "      <td>16.527806</td>\n",
       "      <td>7.866803</td>\n",
       "      <td>15.829717</td>\n",
       "      <td>1.103196</td>\n",
       "      <td>2.222206</td>\n",
       "      <td>10.470586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.522300</td>\n",
       "      <td>985.85000</td>\n",
       "      <td>30.344000</td>\n",
       "      <td>2.087400</td>\n",
       "      <td>17.878000</td>\n",
       "      <td>1000.800000</td>\n",
       "      <td>512.450000</td>\n",
       "      <td>100.170000</td>\n",
       "      <td>9.904400</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>27.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.408000</td>\n",
       "      <td>1008.90000</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>3.723900</td>\n",
       "      <td>23.294000</td>\n",
       "      <td>1079.600000</td>\n",
       "      <td>542.170000</td>\n",
       "      <td>127.985000</td>\n",
       "      <td>11.622000</td>\n",
       "      <td>0.858055</td>\n",
       "      <td>61.303500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.186000</td>\n",
       "      <td>1012.80000</td>\n",
       "      <td>82.266000</td>\n",
       "      <td>4.186200</td>\n",
       "      <td>25.082000</td>\n",
       "      <td>1088.700000</td>\n",
       "      <td>549.890000</td>\n",
       "      <td>133.780000</td>\n",
       "      <td>12.025000</td>\n",
       "      <td>1.390200</td>\n",
       "      <td>66.601000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.862500</td>\n",
       "      <td>1016.90000</td>\n",
       "      <td>90.043500</td>\n",
       "      <td>4.550900</td>\n",
       "      <td>27.184000</td>\n",
       "      <td>1096.000000</td>\n",
       "      <td>550.060000</td>\n",
       "      <td>140.895000</td>\n",
       "      <td>12.578000</td>\n",
       "      <td>2.160400</td>\n",
       "      <td>73.935500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34.929000</td>\n",
       "      <td>1034.20000</td>\n",
       "      <td>100.200000</td>\n",
       "      <td>7.610600</td>\n",
       "      <td>37.402000</td>\n",
       "      <td>1100.800000</td>\n",
       "      <td>550.610000</td>\n",
       "      <td>174.610000</td>\n",
       "      <td>15.081000</td>\n",
       "      <td>44.103000</td>\n",
       "      <td>119.890000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AT           AP            AH          AFDP          GTEP  \\\n",
       "count  15039.000000  15039.00000  15039.000000  15039.000000  15039.000000   \n",
       "mean      17.764381   1013.19924     79.124174      4.200294     25.419061   \n",
       "std        7.574323      6.41076     13.793439      0.760197      4.173916   \n",
       "min        0.522300    985.85000     30.344000      2.087400     17.878000   \n",
       "25%       11.408000   1008.90000     69.750000      3.723900     23.294000   \n",
       "50%       18.186000   1012.80000     82.266000      4.186200     25.082000   \n",
       "75%       23.862500   1016.90000     90.043500      4.550900     27.184000   \n",
       "max       34.929000   1034.20000    100.200000      7.610600     37.402000   \n",
       "\n",
       "                TIT           TAT           TEY           CDP            CO  \\\n",
       "count  15039.000000  15039.000000  15039.000000  15039.000000  15039.000000   \n",
       "mean    1083.798770    545.396183    134.188464     12.102353      1.972499   \n",
       "std       16.527806      7.866803     15.829717      1.103196      2.222206   \n",
       "min     1000.800000    512.450000    100.170000      9.904400      0.000388   \n",
       "25%     1079.600000    542.170000    127.985000     11.622000      0.858055   \n",
       "50%     1088.700000    549.890000    133.780000     12.025000      1.390200   \n",
       "75%     1096.000000    550.060000    140.895000     12.578000      2.160400   \n",
       "max     1100.800000    550.610000    174.610000     15.081000     44.103000   \n",
       "\n",
       "                NOX  \n",
       "count  15039.000000  \n",
       "mean      68.190934  \n",
       "std       10.470586  \n",
       "min       27.765000  \n",
       "25%       61.303500  \n",
       "50%       66.601000  \n",
       "75%       73.935500  \n",
       "max      119.890000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "202d5eb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T07:11:08.512103Z",
     "start_time": "2022-04-29T07:11:05.541347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x20bf2685970>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x=\"CDP\",y=\"TEY\",data=get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec4a9b78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T07:11:29.344404Z",
     "start_time": "2022-04-29T07:11:09.420335Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a9f3944",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T07:11:35.002846Z",
     "start_time": "2022-04-29T07:11:33.969585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 247., 2671.,  474.,  528., 7145.,  462.,  989., 1215., 1160.,\n",
       "         148.]),\n",
       " array([100.17 , 107.614, 115.058, 122.502, 129.946, 137.39 , 144.834,\n",
       "        152.278, 159.722, 167.166, 174.61 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(get['TEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d25b977d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T07:11:44.219195Z",
     "start_time": "2022-04-29T07:11:44.208193Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a96d8e07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T07:11:46.198696Z",
     "start_time": "2022-04-29T07:11:46.151690Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "standardized_get=scaler.fit_transform(get)\n",
    "df=pd.DataFrame(standardized_get, columns=get.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a25d719",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T07:11:47.716085Z",
     "start_time": "2022-04-29T07:11:47.600055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.439778</td>\n",
       "      <td>-0.826644</td>\n",
       "      <td>1.281436</td>\n",
       "      <td>-0.921232</td>\n",
       "      <td>-1.379101</td>\n",
       "      <td>-1.488376</td>\n",
       "      <td>0.585240</td>\n",
       "      <td>-1.231172</td>\n",
       "      <td>-1.357331</td>\n",
       "      <td>0.532012</td>\n",
       "      <td>1.387845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.449601</td>\n",
       "      <td>-0.748647</td>\n",
       "      <td>1.304564</td>\n",
       "      <td>-0.921495</td>\n",
       "      <td>-1.363528</td>\n",
       "      <td>-1.482325</td>\n",
       "      <td>0.585240</td>\n",
       "      <td>-1.229909</td>\n",
       "      <td>-1.363676</td>\n",
       "      <td>0.568733</td>\n",
       "      <td>1.393002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.434721</td>\n",
       "      <td>-0.686250</td>\n",
       "      <td>1.219086</td>\n",
       "      <td>-0.944385</td>\n",
       "      <td>-1.351309</td>\n",
       "      <td>-1.476275</td>\n",
       "      <td>0.568715</td>\n",
       "      <td>-1.230541</td>\n",
       "      <td>-1.360957</td>\n",
       "      <td>0.552938</td>\n",
       "      <td>1.363586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.413702</td>\n",
       "      <td>-0.623853</td>\n",
       "      <td>1.169060</td>\n",
       "      <td>-0.946884</td>\n",
       "      <td>-1.348194</td>\n",
       "      <td>-1.464173</td>\n",
       "      <td>0.583969</td>\n",
       "      <td>-1.229909</td>\n",
       "      <td>-1.356424</td>\n",
       "      <td>0.548933</td>\n",
       "      <td>1.382878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.368693</td>\n",
       "      <td>-0.545857</td>\n",
       "      <td>1.161883</td>\n",
       "      <td>-0.924389</td>\n",
       "      <td>-1.354663</td>\n",
       "      <td>-1.458123</td>\n",
       "      <td>0.582698</td>\n",
       "      <td>-1.229909</td>\n",
       "      <td>-1.350985</td>\n",
       "      <td>0.574179</td>\n",
       "      <td>1.348591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>-1.153182</td>\n",
       "      <td>-1.185428</td>\n",
       "      <td>1.401860</td>\n",
       "      <td>-0.865850</td>\n",
       "      <td>-1.498657</td>\n",
       "      <td>-2.063184</td>\n",
       "      <td>0.103453</td>\n",
       "      <td>-1.426381</td>\n",
       "      <td>-1.543161</td>\n",
       "      <td>1.145792</td>\n",
       "      <td>1.085751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>-1.303986</td>\n",
       "      <td>-1.138630</td>\n",
       "      <td>1.447753</td>\n",
       "      <td>-0.913470</td>\n",
       "      <td>-1.438759</td>\n",
       "      <td>-2.268905</td>\n",
       "      <td>-0.276638</td>\n",
       "      <td>-1.415642</td>\n",
       "      <td>-1.513247</td>\n",
       "      <td>1.293578</td>\n",
       "      <td>1.119943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>-1.386267</td>\n",
       "      <td>-1.076233</td>\n",
       "      <td>1.476971</td>\n",
       "      <td>-0.951488</td>\n",
       "      <td>-1.410967</td>\n",
       "      <td>-2.789257</td>\n",
       "      <td>-1.026650</td>\n",
       "      <td>-1.516089</td>\n",
       "      <td>-1.467922</td>\n",
       "      <td>2.695925</td>\n",
       "      <td>2.170062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>-1.420423</td>\n",
       "      <td>-0.998236</td>\n",
       "      <td>1.441590</td>\n",
       "      <td>-0.988848</td>\n",
       "      <td>-1.447624</td>\n",
       "      <td>-2.456474</td>\n",
       "      <td>-0.528337</td>\n",
       "      <td>-1.481343</td>\n",
       "      <td>-1.422598</td>\n",
       "      <td>1.924683</td>\n",
       "      <td>2.391165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>-1.430734</td>\n",
       "      <td>-0.935839</td>\n",
       "      <td>1.334652</td>\n",
       "      <td>-1.016605</td>\n",
       "      <td>-1.464635</td>\n",
       "      <td>-2.051083</td>\n",
       "      <td>0.057689</td>\n",
       "      <td>-1.428277</td>\n",
       "      <td>-1.377273</td>\n",
       "      <td>1.354150</td>\n",
       "      <td>2.321539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AT        AP        AH      AFDP      GTEP       TIT       TAT  \\\n",
       "0     -1.439778 -0.826644  1.281436 -0.921232 -1.379101 -1.488376  0.585240   \n",
       "1     -1.449601 -0.748647  1.304564 -0.921495 -1.363528 -1.482325  0.585240   \n",
       "2     -1.434721 -0.686250  1.219086 -0.944385 -1.351309 -1.476275  0.568715   \n",
       "3     -1.413702 -0.623853  1.169060 -0.946884 -1.348194 -1.464173  0.583969   \n",
       "4     -1.368693 -0.545857  1.161883 -0.924389 -1.354663 -1.458123  0.582698   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "15034 -1.153182 -1.185428  1.401860 -0.865850 -1.498657 -2.063184  0.103453   \n",
       "15035 -1.303986 -1.138630  1.447753 -0.913470 -1.438759 -2.268905 -0.276638   \n",
       "15036 -1.386267 -1.076233  1.476971 -0.951488 -1.410967 -2.789257 -1.026650   \n",
       "15037 -1.420423 -0.998236  1.441590 -0.988848 -1.447624 -2.456474 -0.528337   \n",
       "15038 -1.430734 -0.935839  1.334652 -1.016605 -1.464635 -2.051083  0.057689   \n",
       "\n",
       "            TEY       CDP        CO       NOX  \n",
       "0     -1.231172 -1.357331  0.532012  1.387845  \n",
       "1     -1.229909 -1.363676  0.568733  1.393002  \n",
       "2     -1.230541 -1.360957  0.552938  1.363586  \n",
       "3     -1.229909 -1.356424  0.548933  1.382878  \n",
       "4     -1.229909 -1.350985  0.574179  1.348591  \n",
       "...         ...       ...       ...       ...  \n",
       "15034 -1.426381 -1.543161  1.145792  1.085751  \n",
       "15035 -1.415642 -1.513247  1.293578  1.119943  \n",
       "15036 -1.516089 -1.467922  2.695925  2.170062  \n",
       "15037 -1.481343 -1.422598  1.924683  2.391165  \n",
       "15038 -1.428277 -1.377273  1.354150  2.321539  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82e999fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T07:11:48.882381Z",
     "start_time": "2022-04-29T07:11:48.842371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15039 entries, 0 to 15038\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AT      15039 non-null  float64\n",
      " 1   AP      15039 non-null  float64\n",
      " 2   AH      15039 non-null  float64\n",
      " 3   AFDP    15039 non-null  float64\n",
      " 4   GTEP    15039 non-null  float64\n",
      " 5   TIT     15039 non-null  float64\n",
      " 6   TAT     15039 non-null  float64\n",
      " 7   TEY     15039 non-null  float64\n",
      " 8   CDP     15039 non-null  float64\n",
      " 9   CO      15039 non-null  float64\n",
      " 10  NOX     15039 non-null  float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4d15426",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T07:11:51.281992Z",
     "start_time": "2022-04-29T07:11:50.938907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "      <td>1.503900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.320107e-16</td>\n",
       "      <td>-1.925280e-14</td>\n",
       "      <td>1.844983e-16</td>\n",
       "      <td>3.810001e-16</td>\n",
       "      <td>1.107344e-16</td>\n",
       "      <td>-2.324212e-15</td>\n",
       "      <td>1.744899e-15</td>\n",
       "      <td>1.406445e-15</td>\n",
       "      <td>3.640356e-16</td>\n",
       "      <td>1.953355e-17</td>\n",
       "      <td>-6.862579e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "      <td>1.000033e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.276462e+00</td>\n",
       "      <td>-4.266288e+00</td>\n",
       "      <td>-3.536594e+00</td>\n",
       "      <td>-2.779497e+00</td>\n",
       "      <td>-1.806771e+00</td>\n",
       "      <td>-5.021933e+00</td>\n",
       "      <td>-4.188141e+00</td>\n",
       "      <td>-2.149097e+00</td>\n",
       "      <td>-1.992416e+00</td>\n",
       "      <td>-8.874862e-01</td>\n",
       "      <td>-3.861033e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.392292e-01</td>\n",
       "      <td>-6.706510e-01</td>\n",
       "      <td>-6.796337e-01</td>\n",
       "      <td>-6.266930e-01</td>\n",
       "      <td>-5.091458e-01</td>\n",
       "      <td>-2.540512e-01</td>\n",
       "      <td>-4.101146e-01</td>\n",
       "      <td>-3.919003e-01</td>\n",
       "      <td>-4.354335e-01</td>\n",
       "      <td>-5.015202e-01</td>\n",
       "      <td>-6.578107e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.566605e-02</td>\n",
       "      <td>-6.227861e-02</td>\n",
       "      <td>2.277844e-01</td>\n",
       "      <td>-1.854065e-02</td>\n",
       "      <td>-8.075681e-02</td>\n",
       "      <td>2.965544e-01</td>\n",
       "      <td>5.712570e-01</td>\n",
       "      <td>-2.580448e-02</td>\n",
       "      <td>-7.011925e-02</td>\n",
       "      <td>-2.620452e-01</td>\n",
       "      <td>-1.518527e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.051309e-01</td>\n",
       "      <td>5.772924e-01</td>\n",
       "      <td>7.916582e-01</td>\n",
       "      <td>4.612196e-01</td>\n",
       "      <td>4.228638e-01</td>\n",
       "      <td>7.382490e-01</td>\n",
       "      <td>5.928675e-01</td>\n",
       "      <td>4.236815e-01</td>\n",
       "      <td>4.311680e-01</td>\n",
       "      <td>8.455882e-02</td>\n",
       "      <td>5.486567e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.266234e+00</td>\n",
       "      <td>3.275970e+00</td>\n",
       "      <td>1.528011e+00</td>\n",
       "      <td>4.486233e+00</td>\n",
       "      <td>2.871006e+00</td>\n",
       "      <td>1.028678e+00</td>\n",
       "      <td>6.627839e-01</td>\n",
       "      <td>2.553607e+00</td>\n",
       "      <td>2.700105e+00</td>\n",
       "      <td>1.895949e+01</td>\n",
       "      <td>4.937717e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AT            AP            AH          AFDP          GTEP  \\\n",
       "count  1.503900e+04  1.503900e+04  1.503900e+04  1.503900e+04  1.503900e+04   \n",
       "mean  -2.320107e-16 -1.925280e-14  1.844983e-16  3.810001e-16  1.107344e-16   \n",
       "std    1.000033e+00  1.000033e+00  1.000033e+00  1.000033e+00  1.000033e+00   \n",
       "min   -2.276462e+00 -4.266288e+00 -3.536594e+00 -2.779497e+00 -1.806771e+00   \n",
       "25%   -8.392292e-01 -6.706510e-01 -6.796337e-01 -6.266930e-01 -5.091458e-01   \n",
       "50%    5.566605e-02 -6.227861e-02  2.277844e-01 -1.854065e-02 -8.075681e-02   \n",
       "75%    8.051309e-01  5.772924e-01  7.916582e-01  4.612196e-01  4.228638e-01   \n",
       "max    2.266234e+00  3.275970e+00  1.528011e+00  4.486233e+00  2.871006e+00   \n",
       "\n",
       "                TIT           TAT           TEY           CDP            CO  \\\n",
       "count  1.503900e+04  1.503900e+04  1.503900e+04  1.503900e+04  1.503900e+04   \n",
       "mean  -2.324212e-15  1.744899e-15  1.406445e-15  3.640356e-16  1.953355e-17   \n",
       "std    1.000033e+00  1.000033e+00  1.000033e+00  1.000033e+00  1.000033e+00   \n",
       "min   -5.021933e+00 -4.188141e+00 -2.149097e+00 -1.992416e+00 -8.874862e-01   \n",
       "25%   -2.540512e-01 -4.101146e-01 -3.919003e-01 -4.354335e-01 -5.015202e-01   \n",
       "50%    2.965544e-01  5.712570e-01 -2.580448e-02 -7.011925e-02 -2.620452e-01   \n",
       "75%    7.382490e-01  5.928675e-01  4.236815e-01  4.311680e-01  8.455882e-02   \n",
       "max    1.028678e+00  6.627839e-01  2.553607e+00  2.700105e+00  1.895949e+01   \n",
       "\n",
       "                NOX  \n",
       "count  1.503900e+04  \n",
       "mean  -6.862579e-17  \n",
       "std    1.000033e+00  \n",
       "min   -3.861033e+00  \n",
       "25%   -6.578107e-01  \n",
       "50%   -1.518527e-01  \n",
       "75%    5.486567e-01  \n",
       "max    4.937717e+00  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "131a33d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T07:11:52.527309Z",
     "start_time": "2022-04-29T07:11:52.494303Z"
    }
   },
   "outputs": [],
   "source": [
    "X=df.drop([\"TEY\"],axis=1)\n",
    "y=df[\"TEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6f7c9e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T07:11:59.932197Z",
     "start_time": "2022-04-29T07:11:59.826170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.439778</td>\n",
       "      <td>-0.826644</td>\n",
       "      <td>1.281436</td>\n",
       "      <td>-0.921232</td>\n",
       "      <td>-1.379101</td>\n",
       "      <td>-1.488376</td>\n",
       "      <td>0.585240</td>\n",
       "      <td>-1.357331</td>\n",
       "      <td>0.532012</td>\n",
       "      <td>1.387845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.449601</td>\n",
       "      <td>-0.748647</td>\n",
       "      <td>1.304564</td>\n",
       "      <td>-0.921495</td>\n",
       "      <td>-1.363528</td>\n",
       "      <td>-1.482325</td>\n",
       "      <td>0.585240</td>\n",
       "      <td>-1.363676</td>\n",
       "      <td>0.568733</td>\n",
       "      <td>1.393002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.434721</td>\n",
       "      <td>-0.686250</td>\n",
       "      <td>1.219086</td>\n",
       "      <td>-0.944385</td>\n",
       "      <td>-1.351309</td>\n",
       "      <td>-1.476275</td>\n",
       "      <td>0.568715</td>\n",
       "      <td>-1.360957</td>\n",
       "      <td>0.552938</td>\n",
       "      <td>1.363586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.413702</td>\n",
       "      <td>-0.623853</td>\n",
       "      <td>1.169060</td>\n",
       "      <td>-0.946884</td>\n",
       "      <td>-1.348194</td>\n",
       "      <td>-1.464173</td>\n",
       "      <td>0.583969</td>\n",
       "      <td>-1.356424</td>\n",
       "      <td>0.548933</td>\n",
       "      <td>1.382878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.368693</td>\n",
       "      <td>-0.545857</td>\n",
       "      <td>1.161883</td>\n",
       "      <td>-0.924389</td>\n",
       "      <td>-1.354663</td>\n",
       "      <td>-1.458123</td>\n",
       "      <td>0.582698</td>\n",
       "      <td>-1.350985</td>\n",
       "      <td>0.574179</td>\n",
       "      <td>1.348591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>-1.153182</td>\n",
       "      <td>-1.185428</td>\n",
       "      <td>1.401860</td>\n",
       "      <td>-0.865850</td>\n",
       "      <td>-1.498657</td>\n",
       "      <td>-2.063184</td>\n",
       "      <td>0.103453</td>\n",
       "      <td>-1.543161</td>\n",
       "      <td>1.145792</td>\n",
       "      <td>1.085751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>-1.303986</td>\n",
       "      <td>-1.138630</td>\n",
       "      <td>1.447753</td>\n",
       "      <td>-0.913470</td>\n",
       "      <td>-1.438759</td>\n",
       "      <td>-2.268905</td>\n",
       "      <td>-0.276638</td>\n",
       "      <td>-1.513247</td>\n",
       "      <td>1.293578</td>\n",
       "      <td>1.119943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>-1.386267</td>\n",
       "      <td>-1.076233</td>\n",
       "      <td>1.476971</td>\n",
       "      <td>-0.951488</td>\n",
       "      <td>-1.410967</td>\n",
       "      <td>-2.789257</td>\n",
       "      <td>-1.026650</td>\n",
       "      <td>-1.467922</td>\n",
       "      <td>2.695925</td>\n",
       "      <td>2.170062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>-1.420423</td>\n",
       "      <td>-0.998236</td>\n",
       "      <td>1.441590</td>\n",
       "      <td>-0.988848</td>\n",
       "      <td>-1.447624</td>\n",
       "      <td>-2.456474</td>\n",
       "      <td>-0.528337</td>\n",
       "      <td>-1.422598</td>\n",
       "      <td>1.924683</td>\n",
       "      <td>2.391165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>-1.430734</td>\n",
       "      <td>-0.935839</td>\n",
       "      <td>1.334652</td>\n",
       "      <td>-1.016605</td>\n",
       "      <td>-1.464635</td>\n",
       "      <td>-2.051083</td>\n",
       "      <td>0.057689</td>\n",
       "      <td>-1.377273</td>\n",
       "      <td>1.354150</td>\n",
       "      <td>2.321539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AT        AP        AH      AFDP      GTEP       TIT       TAT  \\\n",
       "0     -1.439778 -0.826644  1.281436 -0.921232 -1.379101 -1.488376  0.585240   \n",
       "1     -1.449601 -0.748647  1.304564 -0.921495 -1.363528 -1.482325  0.585240   \n",
       "2     -1.434721 -0.686250  1.219086 -0.944385 -1.351309 -1.476275  0.568715   \n",
       "3     -1.413702 -0.623853  1.169060 -0.946884 -1.348194 -1.464173  0.583969   \n",
       "4     -1.368693 -0.545857  1.161883 -0.924389 -1.354663 -1.458123  0.582698   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "15034 -1.153182 -1.185428  1.401860 -0.865850 -1.498657 -2.063184  0.103453   \n",
       "15035 -1.303986 -1.138630  1.447753 -0.913470 -1.438759 -2.268905 -0.276638   \n",
       "15036 -1.386267 -1.076233  1.476971 -0.951488 -1.410967 -2.789257 -1.026650   \n",
       "15037 -1.420423 -0.998236  1.441590 -0.988848 -1.447624 -2.456474 -0.528337   \n",
       "15038 -1.430734 -0.935839  1.334652 -1.016605 -1.464635 -2.051083  0.057689   \n",
       "\n",
       "            CDP        CO       NOX  \n",
       "0     -1.357331  0.532012  1.387845  \n",
       "1     -1.363676  0.568733  1.393002  \n",
       "2     -1.360957  0.552938  1.363586  \n",
       "3     -1.356424  0.548933  1.382878  \n",
       "4     -1.350985  0.574179  1.348591  \n",
       "...         ...       ...       ...  \n",
       "15034 -1.543161  1.145792  1.085751  \n",
       "15035 -1.513247  1.293578  1.119943  \n",
       "15036 -1.467922  2.695925  2.170062  \n",
       "15037 -1.422598  1.924683  2.391165  \n",
       "15038 -1.377273  1.354150  2.321539  \n",
       "\n",
       "[15039 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e70c3154",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T07:12:01.907697Z",
     "start_time": "2022-04-29T07:12:01.863697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       -1.231172\n",
       "1       -1.229909\n",
       "2       -1.230541\n",
       "3       -1.229909\n",
       "4       -1.229909\n",
       "           ...   \n",
       "15034   -1.426381\n",
       "15035   -1.415642\n",
       "15036   -1.516089\n",
       "15037   -1.481343\n",
       "15038   -1.428277\n",
       "Name: TEY, Length: 15039, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31bd078d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T07:12:10.009763Z",
     "start_time": "2022-04-29T07:12:09.997758Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier \n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff408a04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T07:12:11.956254Z",
     "start_time": "2022-04-29T07:12:11.930255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features =X.shape[1]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c43246a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T07:12:19.023055Z",
     "start_time": "2022-04-29T07:12:18.995054Z"
    }
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=n_features, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    optmizer =RMSprop(0.03)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optmizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abbf916e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T17:40:00.180545Z",
     "start_time": "2022-04-28T10:33:03.418923Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\AppData\\Local\\Temp/ipykernel_14512/1391597858.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 1/5; 1/9] END .....batch_size=10, epochs=10;, score=0.000 total time= 1.6min\n",
      "[CV 2/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 2/5; 1/9] END .....batch_size=10, epochs=10;, score=0.000 total time= 1.6min\n",
      "[CV 3/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 3/5; 1/9] END .....batch_size=10, epochs=10;, score=0.000 total time= 1.5min\n",
      "[CV 4/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 4/5; 1/9] END .....batch_size=10, epochs=10;, score=0.000 total time= 1.6min\n",
      "[CV 5/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 5/5; 1/9] END .....batch_size=10, epochs=10;, score=0.000 total time= 2.5min\n",
      "[CV 1/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 1/5; 2/9] END .....batch_size=10, epochs=50;, score=0.000 total time= 7.6min\n",
      "[CV 2/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 2/5; 2/9] END .....batch_size=10, epochs=50;, score=0.000 total time= 8.5min\n",
      "[CV 3/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 3/5; 2/9] END .....batch_size=10, epochs=50;, score=0.000 total time=12.6min\n",
      "[CV 4/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 4/5; 2/9] END .....batch_size=10, epochs=50;, score=0.000 total time=10.1min\n",
      "[CV 5/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 5/5; 2/9] END .....batch_size=10, epochs=50;, score=0.000 total time= 7.7min\n",
      "[CV 1/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 1/5; 3/9] END ....batch_size=10, epochs=100;, score=0.000 total time=35.9min\n",
      "[CV 2/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 2/5; 3/9] END ....batch_size=10, epochs=100;, score=0.000 total time=27.7min\n",
      "[CV 3/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 3/5; 3/9] END ....batch_size=10, epochs=100;, score=0.000 total time=36.9min\n",
      "[CV 4/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 4/5; 3/9] END ....batch_size=10, epochs=100;, score=0.000 total time=63.8min\n",
      "[CV 5/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 5/5; 3/9] END ....batch_size=10, epochs=100;, score=0.000 total time=10.5min\n",
      "[CV 1/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 1/5; 4/9] END .....batch_size=20, epochs=10;, score=0.000 total time=  35.6s\n",
      "[CV 2/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 2/5; 4/9] END .....batch_size=20, epochs=10;, score=0.000 total time= 1.5min\n",
      "[CV 3/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 3/5; 4/9] END .....batch_size=20, epochs=10;, score=0.000 total time=  40.3s\n",
      "[CV 4/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 4/5; 4/9] END .....batch_size=20, epochs=10;, score=0.000 total time=  40.9s\n",
      "[CV 5/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 5/5; 4/9] END .....batch_size=20, epochs=10;, score=0.000 total time=  47.7s\n",
      "[CV 1/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 1/5; 5/9] END .....batch_size=20, epochs=50;, score=0.000 total time= 3.6min\n",
      "[CV 2/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 2/5; 5/9] END .....batch_size=20, epochs=50;, score=0.000 total time= 3.4min\n",
      "[CV 3/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 3/5; 5/9] END .....batch_size=20, epochs=50;, score=0.000 total time= 8.9min\n",
      "[CV 4/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 4/5; 5/9] END .....batch_size=20, epochs=50;, score=0.000 total time= 9.0min\n",
      "[CV 5/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 5/5; 5/9] END .....batch_size=20, epochs=50;, score=0.000 total time= 4.3min\n",
      "[CV 1/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 1/5; 6/9] END ....batch_size=20, epochs=100;, score=0.000 total time=15.1min\n",
      "[CV 2/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 2/5; 6/9] END ....batch_size=20, epochs=100;, score=0.000 total time= 5.7min\n",
      "[CV 3/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 3/5; 6/9] END ....batch_size=20, epochs=100;, score=0.000 total time= 5.0min\n",
      "[CV 4/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 4/5; 6/9] END ....batch_size=20, epochs=100;, score=0.000 total time=25.7min\n",
      "[CV 5/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 5/5; 6/9] END ....batch_size=20, epochs=100;, score=0.000 total time= 6.5min\n",
      "[CV 1/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 1/5; 7/9] END .....batch_size=40, epochs=10;, score=0.000 total time= 6.7min\n",
      "[CV 2/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 2/5; 7/9] END .....batch_size=40, epochs=10;, score=0.000 total time= 7.3min\n",
      "[CV 3/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 3/5; 7/9] END .....batch_size=40, epochs=10;, score=0.000 total time= 8.2min\n",
      "[CV 4/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 4/5; 7/9] END .....batch_size=40, epochs=10;, score=0.000 total time= 7.6min\n",
      "[CV 5/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 5/5; 7/9] END .....batch_size=40, epochs=10;, score=0.000 total time= 3.0min\n",
      "[CV 1/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 1/5; 8/9] END .....batch_size=40, epochs=50;, score=0.000 total time=23.0min\n",
      "[CV 2/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 2/5; 8/9] END .....batch_size=40, epochs=50;, score=0.000 total time= 8.6min\n",
      "[CV 3/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 3/5; 8/9] END .....batch_size=40, epochs=50;, score=0.000 total time= 6.0min\n",
      "[CV 4/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 4/5; 8/9] END .....batch_size=40, epochs=50;, score=0.000 total time= 3.5min\n",
      "[CV 5/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 5/5; 8/9] END .....batch_size=40, epochs=50;, score=0.000 total time= 2.3min\n",
      "[CV 1/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 1/5; 9/9] END ....batch_size=40, epochs=100;, score=0.000 total time= 5.5min\n",
      "[CV 2/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 2/5; 9/9] END ....batch_size=40, epochs=100;, score=0.000 total time= 4.7min\n",
      "[CV 3/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 3/5; 9/9] END ....batch_size=40, epochs=100;, score=0.000 total time= 5.6min\n",
      "[CV 4/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 4/5; 9/9] END ....batch_size=40, epochs=100;, score=0.000 total time= 5.8min\n",
      "[CV 5/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 5/5; 9/9] END ....batch_size=40, epochs=100;, score=0.000 total time= 4.8min\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
    "\n",
    "batch_size = [10,20,40]\n",
    "epochs = [10,50,100]\n",
    "\n",
    "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "755153d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T17:40:02.103033Z",
     "start_time": "2022-04-28T17:40:02.028031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.0, using {'batch_size': 10, 'epochs': 10}\n",
      "0.0,0.0 with: {'batch_size': 10, 'epochs': 10}\n",
      "0.0,0.0 with: {'batch_size': 10, 'epochs': 50}\n",
      "0.0,0.0 with: {'batch_size': 10, 'epochs': 100}\n",
      "0.0,0.0 with: {'batch_size': 20, 'epochs': 10}\n",
      "0.0,0.0 with: {'batch_size': 20, 'epochs': 50}\n",
      "0.0,0.0 with: {'batch_size': 20, 'epochs': 100}\n",
      "0.0,0.0 with: {'batch_size': 40, 'epochs': 10}\n",
      "0.0,0.0 with: {'batch_size': 40, 'epochs': 50}\n",
      "0.0,0.0 with: {'batch_size': 40, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d6bd901",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T17:51:45.931722Z",
     "start_time": "2022-04-28T17:51:45.890713Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b14b5a84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T07:07:14.324937Z",
     "start_time": "2022-04-29T07:07:14.293940Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(learning_rate,dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = n_features,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4,input_dim = n_features,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = learning_rate)\n",
    "    model.compile(loss='mean_squared_error',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f52cd12a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T04:48:23.629695Z",
     "start_time": "2022-04-28T17:52:06.300682Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\AppData\\Local\\Temp/ipykernel_14512/3154034497.py:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 10,epochs = 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time= 3.4min\n",
      "[CV 2/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time= 3.6min\n",
      "[CV 3/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time= 3.0min\n",
      "[CV 4/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time=488.7min\n",
      "[CV 5/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.000 total time= 1.8min\n",
      "[CV 1/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time= 1.1min\n",
      "[CV 2/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time= 1.2min\n",
      "[CV 3/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time= 1.1min\n",
      "[CV 4/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time= 2.2min\n",
      "[CV 5/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.000 total time= 2.5min\n",
      "[CV 1/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time= 2.1min\n",
      "[CV 2/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time= 1.9min\n",
      "[CV 3/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time= 4.7min\n",
      "[CV 4/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time= 2.5min\n",
      "[CV 5/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.000 total time= 1.9min\n",
      "[CV 1/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time= 1.8min\n",
      "[CV 2/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time= 1.6min\n",
      "[CV 3/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time= 1.6min\n",
      "[CV 4/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time= 1.6min\n",
      "[CV 5/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.000 total time= 1.5min\n",
      "[CV 1/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time= 1.4min\n",
      "[CV 2/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time=42.0min\n",
      "[CV 3/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time= 1.5min\n",
      "[CV 4/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time= 1.5min\n",
      "[CV 5/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.000 total time= 1.7min\n",
      "[CV 1/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time= 1.3min\n",
      "[CV 2/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time= 1.1min\n",
      "[CV 3/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time= 2.3min\n",
      "[CV 4/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time= 1.3min\n",
      "[CV 5/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.000 total time= 1.3min\n",
      "[CV 1/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time= 1.1min\n",
      "[CV 2/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time= 1.3min\n",
      "[CV 3/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time= 1.6min\n",
      "[CV 4/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time= 1.2min\n",
      "[CV 5/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.000 total time= 1.2min\n",
      "[CV 1/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time= 1.8min\n",
      "[CV 2/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time= 2.3min\n",
      "[CV 3/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time= 2.3min\n",
      "[CV 4/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time= 2.1min\n",
      "[CV 5/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.000 total time= 2.8min\n",
      "[CV 1/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time= 2.2min\n",
      "[CV 2/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time= 2.2min\n",
      "[CV 3/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time= 4.8min\n",
      "[CV 4/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time= 4.4min\n",
      "[CV 5/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.000 total time=21.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 10,epochs = 10)\n",
    "\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "dropout_rate = [0.0,0.1,0.2]\n",
    "\n",
    "param_grids = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "456cabdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T05:05:29.541226Z",
     "start_time": "2022-04-29T05:05:29.376100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.0, using {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.0,0.0 with: {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.0,0.0 with: {'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
      "0.0,0.0 with: {'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
      "0.0,0.0 with: {'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
      "0.0,0.0 with: {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
      "0.0,0.0 with: {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
      "0.0,0.0 with: {'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
      "0.0,0.0 with: {'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
      "0.0,0.0 with: {'dropout_rate': 0.2, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ecb389f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T07:15:04.632215Z",
     "start_time": "2022-04-29T07:15:04.613211Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = n_features,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    optmizer =RMSprop(0.001)#here,Learning_rate is 0.03\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optmizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f86b1caa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T14:35:31.607588Z",
     "start_time": "2022-04-29T07:15:08.281151Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrmri\\AppData\\Local\\Temp/ipykernel_2456/121926210.py:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 10,epochs = 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n",
      "[CV 1/5; 1/56] START neuron1=4, neuron2=2.......................................\n",
      "[CV 1/5; 1/56] END ........neuron1=4, neuron2=2;, score=0.000 total time= 1.5min\n",
      "[CV 2/5; 1/56] START neuron1=4, neuron2=2.......................................\n",
      "[CV 2/5; 1/56] END ........neuron1=4, neuron2=2;, score=0.000 total time= 1.4min\n",
      "[CV 3/5; 1/56] START neuron1=4, neuron2=2.......................................\n",
      "[CV 3/5; 1/56] END ........neuron1=4, neuron2=2;, score=0.000 total time= 1.4min\n",
      "[CV 4/5; 1/56] START neuron1=4, neuron2=2.......................................\n",
      "[CV 4/5; 1/56] END ........neuron1=4, neuron2=2;, score=0.000 total time= 1.5min\n",
      "[CV 5/5; 1/56] START neuron1=4, neuron2=2.......................................\n",
      "[CV 5/5; 1/56] END ........neuron1=4, neuron2=2;, score=0.000 total time= 1.0min\n",
      "[CV 1/5; 2/56] START neuron1=4, neuron2=4.......................................\n",
      "[CV 1/5; 2/56] END ........neuron1=4, neuron2=4;, score=0.000 total time= 1.0min\n",
      "[CV 2/5; 2/56] START neuron1=4, neuron2=4.......................................\n",
      "[CV 2/5; 2/56] END ........neuron1=4, neuron2=4;, score=0.000 total time= 1.5min\n",
      "[CV 3/5; 2/56] START neuron1=4, neuron2=4.......................................\n",
      "[CV 3/5; 2/56] END ........neuron1=4, neuron2=4;, score=0.000 total time= 1.5min\n",
      "[CV 4/5; 2/56] START neuron1=4, neuron2=4.......................................\n",
      "[CV 4/5; 2/56] END ........neuron1=4, neuron2=4;, score=0.000 total time= 1.5min\n",
      "[CV 5/5; 2/56] START neuron1=4, neuron2=4.......................................\n",
      "[CV 5/5; 2/56] END ........neuron1=4, neuron2=4;, score=0.000 total time= 1.0min\n",
      "[CV 1/5; 3/56] START neuron1=4, neuron2=8.......................................\n",
      "[CV 1/5; 3/56] END ........neuron1=4, neuron2=8;, score=0.000 total time= 1.1min\n",
      "[CV 2/5; 3/56] START neuron1=4, neuron2=8.......................................\n",
      "[CV 2/5; 3/56] END ........neuron1=4, neuron2=8;, score=0.000 total time= 1.1min\n",
      "[CV 3/5; 3/56] START neuron1=4, neuron2=8.......................................\n",
      "[CV 3/5; 3/56] END ........neuron1=4, neuron2=8;, score=0.000 total time= 1.0min\n",
      "[CV 4/5; 3/56] START neuron1=4, neuron2=8.......................................\n",
      "[CV 4/5; 3/56] END ........neuron1=4, neuron2=8;, score=0.000 total time= 1.0min\n",
      "[CV 5/5; 3/56] START neuron1=4, neuron2=8.......................................\n",
      "[CV 5/5; 3/56] END ........neuron1=4, neuron2=8;, score=0.000 total time= 1.5min\n",
      "[CV 1/5; 4/56] START neuron1=4, neuron2=20......................................\n",
      "[CV 1/5; 4/56] END .......neuron1=4, neuron2=20;, score=0.000 total time= 1.2min\n",
      "[CV 2/5; 4/56] START neuron1=4, neuron2=20......................................\n",
      "[CV 2/5; 4/56] END .......neuron1=4, neuron2=20;, score=0.000 total time= 1.0min\n",
      "[CV 3/5; 4/56] START neuron1=4, neuron2=20......................................\n",
      "[CV 3/5; 4/56] END .......neuron1=4, neuron2=20;, score=0.000 total time= 1.0min\n",
      "[CV 4/5; 4/56] START neuron1=4, neuron2=20......................................\n",
      "[CV 4/5; 4/56] END .......neuron1=4, neuron2=20;, score=0.000 total time= 1.5min\n",
      "[CV 5/5; 4/56] START neuron1=4, neuron2=20......................................\n",
      "[CV 5/5; 4/56] END .......neuron1=4, neuron2=20;, score=0.000 total time= 1.5min\n",
      "[CV 1/5; 5/56] START neuron1=4, neuron2=30......................................\n",
      "[CV 1/5; 5/56] END .......neuron1=4, neuron2=30;, score=0.000 total time= 1.1min\n",
      "[CV 2/5; 5/56] START neuron1=4, neuron2=30......................................\n",
      "[CV 2/5; 5/56] END .......neuron1=4, neuron2=30;, score=0.000 total time= 1.2min\n",
      "[CV 3/5; 5/56] START neuron1=4, neuron2=30......................................\n",
      "[CV 3/5; 5/56] END .......neuron1=4, neuron2=30;, score=0.000 total time= 1.1min\n",
      "[CV 4/5; 5/56] START neuron1=4, neuron2=30......................................\n",
      "[CV 4/5; 5/56] END .......neuron1=4, neuron2=30;, score=0.000 total time= 1.1min\n",
      "[CV 5/5; 5/56] START neuron1=4, neuron2=30......................................\n",
      "[CV 5/5; 5/56] END .......neuron1=4, neuron2=30;, score=0.000 total time= 1.1min\n",
      "[CV 1/5; 6/56] START neuron1=4, neuron2=40......................................\n",
      "[CV 1/5; 6/56] END .......neuron1=4, neuron2=40;, score=0.000 total time= 1.5min\n",
      "[CV 2/5; 6/56] START neuron1=4, neuron2=40......................................\n",
      "[CV 2/5; 6/56] END .......neuron1=4, neuron2=40;, score=0.000 total time= 1.1min\n",
      "[CV 3/5; 6/56] START neuron1=4, neuron2=40......................................\n",
      "[CV 3/5; 6/56] END .......neuron1=4, neuron2=40;, score=0.000 total time= 1.2min\n",
      "[CV 4/5; 6/56] START neuron1=4, neuron2=40......................................\n",
      "[CV 4/5; 6/56] END .......neuron1=4, neuron2=40;, score=0.000 total time= 1.2min\n",
      "[CV 5/5; 6/56] START neuron1=4, neuron2=40......................................\n",
      "[CV 5/5; 6/56] END .......neuron1=4, neuron2=40;, score=0.000 total time= 1.1min\n",
      "[CV 1/5; 7/56] START neuron1=4, neuron2=50......................................\n",
      "[CV 1/5; 7/56] END .......neuron1=4, neuron2=50;, score=0.000 total time= 1.5min\n",
      "[CV 2/5; 7/56] START neuron1=4, neuron2=50......................................\n",
      "[CV 2/5; 7/56] END .......neuron1=4, neuron2=50;, score=0.000 total time= 1.1min\n",
      "[CV 3/5; 7/56] START neuron1=4, neuron2=50......................................\n",
      "[CV 3/5; 7/56] END .......neuron1=4, neuron2=50;, score=0.000 total time= 1.2min\n",
      "[CV 4/5; 7/56] START neuron1=4, neuron2=50......................................\n",
      "[CV 4/5; 7/56] END .......neuron1=4, neuron2=50;, score=0.000 total time= 1.5min\n",
      "[CV 5/5; 7/56] START neuron1=4, neuron2=50......................................\n",
      "[CV 5/5; 7/56] END .......neuron1=4, neuron2=50;, score=0.000 total time= 1.1min\n",
      "[CV 1/5; 8/56] START neuron1=4, neuron2=60......................................\n",
      "[CV 1/5; 8/56] END .......neuron1=4, neuron2=60;, score=0.000 total time= 1.2min\n",
      "[CV 2/5; 8/56] START neuron1=4, neuron2=60......................................\n",
      "[CV 2/5; 8/56] END .......neuron1=4, neuron2=60;, score=0.000 total time= 1.2min\n",
      "[CV 3/5; 8/56] START neuron1=4, neuron2=60......................................\n",
      "[CV 3/5; 8/56] END .......neuron1=4, neuron2=60;, score=0.000 total time= 1.1min\n",
      "[CV 4/5; 8/56] START neuron1=4, neuron2=60......................................\n",
      "[CV 4/5; 8/56] END .......neuron1=4, neuron2=60;, score=0.000 total time= 1.2min\n",
      "[CV 5/5; 8/56] START neuron1=4, neuron2=60......................................\n",
      "[CV 5/5; 8/56] END .......neuron1=4, neuron2=60;, score=0.000 total time= 1.5min\n",
      "[CV 1/5; 9/56] START neuron1=8, neuron2=2.......................................\n",
      "[CV 1/5; 9/56] END ........neuron1=8, neuron2=2;, score=0.000 total time= 1.5min\n",
      "[CV 2/5; 9/56] START neuron1=8, neuron2=2.......................................\n",
      "[CV 2/5; 9/56] END ........neuron1=8, neuron2=2;, score=0.000 total time= 1.1min\n",
      "[CV 3/5; 9/56] START neuron1=8, neuron2=2.......................................\n",
      "[CV 3/5; 9/56] END ........neuron1=8, neuron2=2;, score=0.000 total time= 1.1min\n",
      "[CV 4/5; 9/56] START neuron1=8, neuron2=2.......................................\n",
      "[CV 4/5; 9/56] END ........neuron1=8, neuron2=2;, score=0.000 total time= 1.1min\n",
      "[CV 5/5; 9/56] START neuron1=8, neuron2=2.......................................\n",
      "[CV 5/5; 9/56] END ........neuron1=8, neuron2=2;, score=0.000 total time= 1.5min\n",
      "[CV 1/5; 10/56] START neuron1=8, neuron2=4......................................\n",
      "[CV 1/5; 10/56] END .......neuron1=8, neuron2=4;, score=0.000 total time= 1.3min\n",
      "[CV 2/5; 10/56] START neuron1=8, neuron2=4......................................\n",
      "[CV 2/5; 10/56] END .......neuron1=8, neuron2=4;, score=0.000 total time= 1.3min\n",
      "[CV 3/5; 10/56] START neuron1=8, neuron2=4......................................\n",
      "[CV 3/5; 10/56] END .......neuron1=8, neuron2=4;, score=0.000 total time= 1.2min\n",
      "[CV 4/5; 10/56] START neuron1=8, neuron2=4......................................\n",
      "[CV 4/5; 10/56] END .......neuron1=8, neuron2=4;, score=0.000 total time= 1.2min\n",
      "[CV 5/5; 10/56] START neuron1=8, neuron2=4......................................\n",
      "[CV 5/5; 10/56] END .......neuron1=8, neuron2=4;, score=0.000 total time= 1.2min\n",
      "[CV 1/5; 11/56] START neuron1=8, neuron2=8......................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 11/56] END .......neuron1=8, neuron2=8;, score=0.000 total time= 1.2min\n",
      "[CV 2/5; 11/56] START neuron1=8, neuron2=8......................................\n",
      "[CV 2/5; 11/56] END .......neuron1=8, neuron2=8;, score=0.000 total time= 1.2min\n",
      "[CV 3/5; 11/56] START neuron1=8, neuron2=8......................................\n",
      "[CV 3/5; 11/56] END .......neuron1=8, neuron2=8;, score=0.000 total time= 1.2min\n",
      "[CV 4/5; 11/56] START neuron1=8, neuron2=8......................................\n",
      "[CV 4/5; 11/56] END .......neuron1=8, neuron2=8;, score=0.000 total time= 1.5min\n",
      "[CV 5/5; 11/56] START neuron1=8, neuron2=8......................................\n",
      "[CV 5/5; 11/56] END .......neuron1=8, neuron2=8;, score=0.000 total time= 1.1min\n",
      "[CV 1/5; 12/56] START neuron1=8, neuron2=20.....................................\n",
      "[CV 1/5; 12/56] END ......neuron1=8, neuron2=20;, score=0.000 total time= 1.1min\n",
      "[CV 2/5; 12/56] START neuron1=8, neuron2=20.....................................\n",
      "[CV 2/5; 12/56] END ......neuron1=8, neuron2=20;, score=0.000 total time= 1.2min\n",
      "[CV 3/5; 12/56] START neuron1=8, neuron2=20.....................................\n",
      "[CV 3/5; 12/56] END ......neuron1=8, neuron2=20;, score=0.000 total time= 1.5min\n",
      "[CV 4/5; 12/56] START neuron1=8, neuron2=20.....................................\n",
      "[CV 4/5; 12/56] END ......neuron1=8, neuron2=20;, score=0.000 total time= 1.2min\n",
      "[CV 5/5; 12/56] START neuron1=8, neuron2=20.....................................\n",
      "[CV 5/5; 12/56] END ......neuron1=8, neuron2=20;, score=0.000 total time= 1.1min\n",
      "[CV 1/5; 13/56] START neuron1=8, neuron2=30.....................................\n",
      "[CV 1/5; 13/56] END ......neuron1=8, neuron2=30;, score=0.000 total time= 1.2min\n",
      "[CV 2/5; 13/56] START neuron1=8, neuron2=30.....................................\n",
      "[CV 2/5; 13/56] END ......neuron1=8, neuron2=30;, score=0.000 total time= 1.1min\n",
      "[CV 3/5; 13/56] START neuron1=8, neuron2=30.....................................\n",
      "[CV 3/5; 13/56] END ......neuron1=8, neuron2=30;, score=0.000 total time= 1.1min\n",
      "[CV 4/5; 13/56] START neuron1=8, neuron2=30.....................................\n",
      "[CV 4/5; 13/56] END ......neuron1=8, neuron2=30;, score=0.000 total time= 1.1min\n",
      "[CV 5/5; 13/56] START neuron1=8, neuron2=30.....................................\n",
      "[CV 5/5; 13/56] END ......neuron1=8, neuron2=30;, score=0.000 total time= 1.1min\n",
      "[CV 1/5; 14/56] START neuron1=8, neuron2=40.....................................\n",
      "[CV 1/5; 14/56] END ......neuron1=8, neuron2=40;, score=0.000 total time= 1.5min\n",
      "[CV 2/5; 14/56] START neuron1=8, neuron2=40.....................................\n",
      "[CV 2/5; 14/56] END ......neuron1=8, neuron2=40;, score=0.000 total time= 1.1min\n",
      "[CV 3/5; 14/56] START neuron1=8, neuron2=40.....................................\n",
      "[CV 3/5; 14/56] END ......neuron1=8, neuron2=40;, score=0.000 total time= 1.5min\n",
      "[CV 4/5; 14/56] START neuron1=8, neuron2=40.....................................\n",
      "[CV 4/5; 14/56] END ......neuron1=8, neuron2=40;, score=0.000 total time= 1.1min\n",
      "[CV 5/5; 14/56] START neuron1=8, neuron2=40.....................................\n",
      "[CV 5/5; 14/56] END ......neuron1=8, neuron2=40;, score=0.000 total time= 1.1min\n",
      "[CV 1/5; 15/56] START neuron1=8, neuron2=50.....................................\n",
      "[CV 1/5; 15/56] END ......neuron1=8, neuron2=50;, score=0.000 total time= 1.1min\n",
      "[CV 2/5; 15/56] START neuron1=8, neuron2=50.....................................\n",
      "[CV 2/5; 15/56] END ......neuron1=8, neuron2=50;, score=0.000 total time= 1.1min\n",
      "[CV 3/5; 15/56] START neuron1=8, neuron2=50.....................................\n",
      "[CV 3/5; 15/56] END ......neuron1=8, neuron2=50;, score=0.000 total time= 1.1min\n",
      "[CV 4/5; 15/56] START neuron1=8, neuron2=50.....................................\n",
      "[CV 4/5; 15/56] END ......neuron1=8, neuron2=50;, score=0.000 total time= 1.2min\n",
      "[CV 5/5; 15/56] START neuron1=8, neuron2=50.....................................\n",
      "[CV 5/5; 15/56] END ......neuron1=8, neuron2=50;, score=0.000 total time= 1.2min\n",
      "[CV 1/5; 16/56] START neuron1=8, neuron2=60.....................................\n",
      "[CV 1/5; 16/56] END ......neuron1=8, neuron2=60;, score=0.000 total time= 1.2min\n",
      "[CV 2/5; 16/56] START neuron1=8, neuron2=60.....................................\n",
      "[CV 2/5; 16/56] END ......neuron1=8, neuron2=60;, score=0.000 total time= 1.5min\n",
      "[CV 3/5; 16/56] START neuron1=8, neuron2=60.....................................\n",
      "[CV 3/5; 16/56] END ......neuron1=8, neuron2=60;, score=0.000 total time= 1.1min\n",
      "[CV 4/5; 16/56] START neuron1=8, neuron2=60.....................................\n",
      "[CV 4/5; 16/56] END ......neuron1=8, neuron2=60;, score=0.000 total time= 1.1min\n",
      "[CV 5/5; 16/56] START neuron1=8, neuron2=60.....................................\n",
      "[CV 5/5; 16/56] END ......neuron1=8, neuron2=60;, score=0.000 total time= 1.3min\n",
      "[CV 1/5; 17/56] START neuron1=16, neuron2=2.....................................\n",
      "[CV 1/5; 17/56] END ......neuron1=16, neuron2=2;, score=0.000 total time= 1.5min\n",
      "[CV 2/5; 17/56] START neuron1=16, neuron2=2.....................................\n",
      "[CV 2/5; 17/56] END ......neuron1=16, neuron2=2;, score=0.000 total time= 2.7min\n",
      "[CV 3/5; 17/56] START neuron1=16, neuron2=2.....................................\n",
      "[CV 3/5; 17/56] END ......neuron1=16, neuron2=2;, score=0.000 total time= 2.8min\n",
      "[CV 4/5; 17/56] START neuron1=16, neuron2=2.....................................\n",
      "[CV 4/5; 17/56] END ......neuron1=16, neuron2=2;, score=0.000 total time= 1.7min\n",
      "[CV 5/5; 17/56] START neuron1=16, neuron2=2.....................................\n",
      "[CV 5/5; 17/56] END ......neuron1=16, neuron2=2;, score=0.000 total time= 1.1min\n",
      "[CV 1/5; 18/56] START neuron1=16, neuron2=4.....................................\n",
      "[CV 1/5; 18/56] END ......neuron1=16, neuron2=4;, score=0.000 total time= 1.1min\n",
      "[CV 2/5; 18/56] START neuron1=16, neuron2=4.....................................\n",
      "[CV 2/5; 18/56] END ......neuron1=16, neuron2=4;, score=0.000 total time= 1.2min\n",
      "[CV 3/5; 18/56] START neuron1=16, neuron2=4.....................................\n",
      "[CV 3/5; 18/56] END ......neuron1=16, neuron2=4;, score=0.000 total time= 1.4min\n",
      "[CV 4/5; 18/56] START neuron1=16, neuron2=4.....................................\n",
      "[CV 4/5; 18/56] END ......neuron1=16, neuron2=4;, score=0.000 total time= 1.3min\n",
      "[CV 5/5; 18/56] START neuron1=16, neuron2=4.....................................\n",
      "[CV 5/5; 18/56] END ......neuron1=16, neuron2=4;, score=0.000 total time= 1.4min\n",
      "[CV 1/5; 19/56] START neuron1=16, neuron2=8.....................................\n",
      "[CV 1/5; 19/56] END ......neuron1=16, neuron2=8;, score=0.000 total time= 1.1min\n",
      "[CV 2/5; 19/56] START neuron1=16, neuron2=8.....................................\n",
      "[CV 2/5; 19/56] END ......neuron1=16, neuron2=8;, score=0.000 total time= 1.1min\n",
      "[CV 3/5; 19/56] START neuron1=16, neuron2=8.....................................\n",
      "[CV 3/5; 19/56] END ......neuron1=16, neuron2=8;, score=0.000 total time= 1.1min\n",
      "[CV 4/5; 19/56] START neuron1=16, neuron2=8.....................................\n",
      "[CV 4/5; 19/56] END ......neuron1=16, neuron2=8;, score=0.000 total time= 1.5min\n",
      "[CV 5/5; 19/56] START neuron1=16, neuron2=8.....................................\n",
      "[CV 5/5; 19/56] END ......neuron1=16, neuron2=8;, score=0.000 total time= 1.5min\n",
      "[CV 1/5; 20/56] START neuron1=16, neuron2=20....................................\n",
      "[CV 1/5; 20/56] END .....neuron1=16, neuron2=20;, score=0.000 total time= 1.1min\n",
      "[CV 2/5; 20/56] START neuron1=16, neuron2=20....................................\n",
      "[CV 2/5; 20/56] END .....neuron1=16, neuron2=20;, score=0.000 total time= 1.1min\n",
      "[CV 3/5; 20/56] START neuron1=16, neuron2=20....................................\n",
      "[CV 3/5; 20/56] END .....neuron1=16, neuron2=20;, score=0.000 total time= 1.2min\n",
      "[CV 4/5; 20/56] START neuron1=16, neuron2=20....................................\n",
      "[CV 4/5; 20/56] END .....neuron1=16, neuron2=20;, score=0.000 total time= 1.4min\n",
      "[CV 5/5; 20/56] START neuron1=16, neuron2=20....................................\n",
      "[CV 5/5; 20/56] END .....neuron1=16, neuron2=20;, score=0.000 total time= 1.1min\n",
      "[CV 1/5; 21/56] START neuron1=16, neuron2=30....................................\n",
      "[CV 1/5; 21/56] END .....neuron1=16, neuron2=30;, score=0.000 total time= 1.1min\n",
      "[CV 2/5; 21/56] START neuron1=16, neuron2=30....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 21/56] END .....neuron1=16, neuron2=30;, score=0.000 total time= 1.0min\n",
      "[CV 3/5; 21/56] START neuron1=16, neuron2=30....................................\n",
      "[CV 3/5; 21/56] END .....neuron1=16, neuron2=30;, score=0.000 total time= 1.5min\n",
      "[CV 4/5; 21/56] START neuron1=16, neuron2=30....................................\n",
      "[CV 4/5; 21/56] END .....neuron1=16, neuron2=30;, score=0.000 total time= 2.2min\n",
      "[CV 5/5; 21/56] START neuron1=16, neuron2=30....................................\n",
      "[CV 5/5; 21/56] END .....neuron1=16, neuron2=30;, score=0.000 total time= 1.1min\n",
      "[CV 1/5; 22/56] START neuron1=16, neuron2=40....................................\n",
      "[CV 1/5; 22/56] END .....neuron1=16, neuron2=40;, score=0.000 total time= 1.2min\n",
      "[CV 2/5; 22/56] START neuron1=16, neuron2=40....................................\n",
      "[CV 2/5; 22/56] END .....neuron1=16, neuron2=40;, score=0.000 total time= 1.1min\n",
      "[CV 3/5; 22/56] START neuron1=16, neuron2=40....................................\n",
      "[CV 3/5; 22/56] END .....neuron1=16, neuron2=40;, score=0.000 total time= 1.2min\n",
      "[CV 4/5; 22/56] START neuron1=16, neuron2=40....................................\n",
      "[CV 4/5; 22/56] END .....neuron1=16, neuron2=40;, score=0.000 total time= 1.2min\n",
      "[CV 5/5; 22/56] START neuron1=16, neuron2=40....................................\n",
      "[CV 5/5; 22/56] END .....neuron1=16, neuron2=40;, score=0.000 total time= 1.5min\n",
      "[CV 1/5; 23/56] START neuron1=16, neuron2=50....................................\n",
      "[CV 1/5; 23/56] END .....neuron1=16, neuron2=50;, score=0.000 total time= 1.2min\n",
      "[CV 2/5; 23/56] START neuron1=16, neuron2=50....................................\n",
      "[CV 2/5; 23/56] END .....neuron1=16, neuron2=50;, score=0.000 total time= 1.1min\n",
      "[CV 3/5; 23/56] START neuron1=16, neuron2=50....................................\n",
      "[CV 3/5; 23/56] END .....neuron1=16, neuron2=50;, score=0.000 total time= 1.0min\n",
      "[CV 4/5; 23/56] START neuron1=16, neuron2=50....................................\n",
      "[CV 4/5; 23/56] END .....neuron1=16, neuron2=50;, score=0.000 total time= 1.1min\n",
      "[CV 5/5; 23/56] START neuron1=16, neuron2=50....................................\n",
      "[CV 5/5; 23/56] END .....neuron1=16, neuron2=50;, score=0.000 total time= 2.0min\n",
      "[CV 1/5; 24/56] START neuron1=16, neuron2=60....................................\n",
      "[CV 1/5; 24/56] END .....neuron1=16, neuron2=60;, score=0.000 total time= 4.2min\n",
      "[CV 2/5; 24/56] START neuron1=16, neuron2=60....................................\n",
      "[CV 2/5; 24/56] END .....neuron1=16, neuron2=60;, score=0.000 total time= 2.7min\n",
      "[CV 3/5; 24/56] START neuron1=16, neuron2=60....................................\n",
      "[CV 3/5; 24/56] END .....neuron1=16, neuron2=60;, score=0.000 total time= 4.1min\n",
      "[CV 4/5; 24/56] START neuron1=16, neuron2=60....................................\n",
      "[CV 4/5; 24/56] END .....neuron1=16, neuron2=60;, score=0.000 total time= 3.2min\n",
      "[CV 5/5; 24/56] START neuron1=16, neuron2=60....................................\n",
      "[CV 5/5; 24/56] END .....neuron1=16, neuron2=60;, score=0.000 total time= 1.2min\n",
      "[CV 1/5; 25/56] START neuron1=20, neuron2=2.....................................\n",
      "[CV 1/5; 25/56] END ......neuron1=20, neuron2=2;, score=0.000 total time= 1.2min\n",
      "[CV 2/5; 25/56] START neuron1=20, neuron2=2.....................................\n",
      "[CV 2/5; 25/56] END ......neuron1=20, neuron2=2;, score=0.000 total time= 1.2min\n",
      "[CV 3/5; 25/56] START neuron1=20, neuron2=2.....................................\n",
      "[CV 3/5; 25/56] END ......neuron1=20, neuron2=2;, score=0.000 total time= 1.3min\n",
      "[CV 4/5; 25/56] START neuron1=20, neuron2=2.....................................\n",
      "[CV 4/5; 25/56] END ......neuron1=20, neuron2=2;, score=0.000 total time= 1.5min\n",
      "[CV 5/5; 25/56] START neuron1=20, neuron2=2.....................................\n",
      "[CV 5/5; 25/56] END ......neuron1=20, neuron2=2;, score=0.000 total time= 1.1min\n",
      "[CV 1/5; 26/56] START neuron1=20, neuron2=4.....................................\n",
      "[CV 1/5; 26/56] END ......neuron1=20, neuron2=4;, score=0.000 total time= 1.1min\n",
      "[CV 2/5; 26/56] START neuron1=20, neuron2=4.....................................\n",
      "[CV 2/5; 26/56] END ......neuron1=20, neuron2=4;, score=0.000 total time= 4.8min\n",
      "[CV 3/5; 26/56] START neuron1=20, neuron2=4.....................................\n",
      "[CV 3/5; 26/56] END ......neuron1=20, neuron2=4;, score=0.000 total time= 3.2min\n",
      "[CV 4/5; 26/56] START neuron1=20, neuron2=4.....................................\n",
      "[CV 4/5; 26/56] END ......neuron1=20, neuron2=4;, score=0.000 total time= 5.0min\n",
      "[CV 5/5; 26/56] START neuron1=20, neuron2=4.....................................\n",
      "[CV 5/5; 26/56] END ......neuron1=20, neuron2=4;, score=0.000 total time= 5.4min\n",
      "[CV 1/5; 27/56] START neuron1=20, neuron2=8.....................................\n",
      "[CV 1/5; 27/56] END ......neuron1=20, neuron2=8;, score=0.000 total time= 3.9min\n",
      "[CV 2/5; 27/56] START neuron1=20, neuron2=8.....................................\n",
      "[CV 2/5; 27/56] END ......neuron1=20, neuron2=8;, score=0.000 total time= 4.9min\n",
      "[CV 3/5; 27/56] START neuron1=20, neuron2=8.....................................\n",
      "[CV 3/5; 27/56] END ......neuron1=20, neuron2=8;, score=0.000 total time= 4.2min\n",
      "[CV 4/5; 27/56] START neuron1=20, neuron2=8.....................................\n",
      "[CV 4/5; 27/56] END ......neuron1=20, neuron2=8;, score=0.000 total time= 2.7min\n",
      "[CV 5/5; 27/56] START neuron1=20, neuron2=8.....................................\n",
      "[CV 5/5; 27/56] END ......neuron1=20, neuron2=8;, score=0.000 total time= 2.6min\n",
      "[CV 1/5; 28/56] START neuron1=20, neuron2=20....................................\n",
      "[CV 1/5; 28/56] END .....neuron1=20, neuron2=20;, score=0.000 total time= 1.5min\n",
      "[CV 2/5; 28/56] START neuron1=20, neuron2=20....................................\n",
      "[CV 2/5; 28/56] END .....neuron1=20, neuron2=20;, score=0.000 total time= 1.3min\n",
      "[CV 3/5; 28/56] START neuron1=20, neuron2=20....................................\n",
      "[CV 3/5; 28/56] END .....neuron1=20, neuron2=20;, score=0.000 total time= 1.5min\n",
      "[CV 4/5; 28/56] START neuron1=20, neuron2=20....................................\n",
      "[CV 4/5; 28/56] END .....neuron1=20, neuron2=20;, score=0.000 total time= 1.5min\n",
      "[CV 5/5; 28/56] START neuron1=20, neuron2=20....................................\n",
      "[CV 5/5; 28/56] END .....neuron1=20, neuron2=20;, score=0.000 total time= 1.3min\n",
      "[CV 1/5; 29/56] START neuron1=20, neuron2=30....................................\n",
      "[CV 1/5; 29/56] END .....neuron1=20, neuron2=30;, score=0.000 total time= 1.2min\n",
      "[CV 2/5; 29/56] START neuron1=20, neuron2=30....................................\n",
      "[CV 2/5; 29/56] END .....neuron1=20, neuron2=30;, score=0.000 total time= 1.2min\n",
      "[CV 3/5; 29/56] START neuron1=20, neuron2=30....................................\n",
      "[CV 3/5; 29/56] END .....neuron1=20, neuron2=30;, score=0.000 total time= 1.7min\n",
      "[CV 4/5; 29/56] START neuron1=20, neuron2=30....................................\n",
      "[CV 4/5; 29/56] END .....neuron1=20, neuron2=30;, score=0.000 total time= 2.5min\n",
      "[CV 5/5; 29/56] START neuron1=20, neuron2=30....................................\n",
      "[CV 5/5; 29/56] END .....neuron1=20, neuron2=30;, score=0.000 total time= 1.5min\n",
      "[CV 1/5; 30/56] START neuron1=20, neuron2=40....................................\n",
      "[CV 1/5; 30/56] END .....neuron1=20, neuron2=40;, score=0.000 total time= 2.6min\n",
      "[CV 2/5; 30/56] START neuron1=20, neuron2=40....................................\n",
      "[CV 2/5; 30/56] END .....neuron1=20, neuron2=40;, score=0.000 total time= 1.2min\n",
      "[CV 3/5; 30/56] START neuron1=20, neuron2=40....................................\n",
      "[CV 3/5; 30/56] END .....neuron1=20, neuron2=40;, score=0.000 total time= 1.3min\n",
      "[CV 4/5; 30/56] START neuron1=20, neuron2=40....................................\n",
      "[CV 4/5; 30/56] END .....neuron1=20, neuron2=40;, score=0.000 total time= 1.5min\n",
      "[CV 5/5; 30/56] START neuron1=20, neuron2=40....................................\n",
      "[CV 5/5; 30/56] END .....neuron1=20, neuron2=40;, score=0.000 total time= 1.5min\n",
      "[CV 1/5; 31/56] START neuron1=20, neuron2=50....................................\n",
      "[CV 1/5; 31/56] END .....neuron1=20, neuron2=50;, score=0.000 total time= 1.2min\n",
      "[CV 2/5; 31/56] START neuron1=20, neuron2=50....................................\n",
      "[CV 2/5; 31/56] END .....neuron1=20, neuron2=50;, score=0.000 total time= 1.2min\n",
      "[CV 3/5; 31/56] START neuron1=20, neuron2=50....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 31/56] END .....neuron1=20, neuron2=50;, score=0.000 total time= 1.2min\n",
      "[CV 4/5; 31/56] START neuron1=20, neuron2=50....................................\n",
      "[CV 4/5; 31/56] END .....neuron1=20, neuron2=50;, score=0.000 total time= 1.1min\n",
      "[CV 5/5; 31/56] START neuron1=20, neuron2=50....................................\n",
      "[CV 5/5; 31/56] END .....neuron1=20, neuron2=50;, score=0.000 total time= 1.2min\n",
      "[CV 1/5; 32/56] START neuron1=20, neuron2=60....................................\n",
      "[CV 1/5; 32/56] END .....neuron1=20, neuron2=60;, score=0.000 total time= 1.3min\n",
      "[CV 2/5; 32/56] START neuron1=20, neuron2=60....................................\n",
      "[CV 2/5; 32/56] END .....neuron1=20, neuron2=60;, score=0.000 total time= 1.3min\n",
      "[CV 3/5; 32/56] START neuron1=20, neuron2=60....................................\n",
      "[CV 3/5; 32/56] END .....neuron1=20, neuron2=60;, score=0.000 total time= 1.4min\n",
      "[CV 4/5; 32/56] START neuron1=20, neuron2=60....................................\n",
      "[CV 4/5; 32/56] END .....neuron1=20, neuron2=60;, score=0.000 total time= 1.6min\n",
      "[CV 5/5; 32/56] START neuron1=20, neuron2=60....................................\n",
      "[CV 5/5; 32/56] END .....neuron1=20, neuron2=60;, score=0.000 total time= 1.5min\n",
      "[CV 1/5; 33/56] START neuron1=30, neuron2=2.....................................\n",
      "[CV 1/5; 33/56] END ......neuron1=30, neuron2=2;, score=0.000 total time= 1.1min\n",
      "[CV 2/5; 33/56] START neuron1=30, neuron2=2.....................................\n",
      "[CV 2/5; 33/56] END ......neuron1=30, neuron2=2;, score=0.000 total time= 1.2min\n",
      "[CV 3/5; 33/56] START neuron1=30, neuron2=2.....................................\n",
      "[CV 3/5; 33/56] END ......neuron1=30, neuron2=2;, score=0.000 total time= 1.2min\n",
      "[CV 4/5; 33/56] START neuron1=30, neuron2=2.....................................\n",
      "[CV 4/5; 33/56] END ......neuron1=30, neuron2=2;, score=0.000 total time= 1.2min\n",
      "[CV 5/5; 33/56] START neuron1=30, neuron2=2.....................................\n",
      "[CV 5/5; 33/56] END ......neuron1=30, neuron2=2;, score=0.000 total time= 1.2min\n",
      "[CV 1/5; 34/56] START neuron1=30, neuron2=4.....................................\n",
      "[CV 1/5; 34/56] END ......neuron1=30, neuron2=4;, score=0.000 total time= 1.2min\n",
      "[CV 2/5; 34/56] START neuron1=30, neuron2=4.....................................\n",
      "[CV 2/5; 34/56] END ......neuron1=30, neuron2=4;, score=0.000 total time= 1.6min\n",
      "[CV 3/5; 34/56] START neuron1=30, neuron2=4.....................................\n",
      "[CV 3/5; 34/56] END ......neuron1=30, neuron2=4;, score=0.000 total time= 1.2min\n",
      "[CV 4/5; 34/56] START neuron1=30, neuron2=4.....................................\n",
      "[CV 4/5; 34/56] END ......neuron1=30, neuron2=4;, score=0.000 total time= 1.2min\n",
      "[CV 5/5; 34/56] START neuron1=30, neuron2=4.....................................\n",
      "[CV 5/5; 34/56] END ......neuron1=30, neuron2=4;, score=0.000 total time= 1.2min\n",
      "[CV 1/5; 35/56] START neuron1=30, neuron2=8.....................................\n",
      "[CV 1/5; 35/56] END ......neuron1=30, neuron2=8;, score=0.000 total time= 1.6min\n",
      "[CV 2/5; 35/56] START neuron1=30, neuron2=8.....................................\n",
      "[CV 2/5; 35/56] END ......neuron1=30, neuron2=8;, score=0.000 total time= 1.4min\n",
      "[CV 3/5; 35/56] START neuron1=30, neuron2=8.....................................\n",
      "[CV 3/5; 35/56] END ......neuron1=30, neuron2=8;, score=0.000 total time=  47.1s\n",
      "[CV 4/5; 35/56] START neuron1=30, neuron2=8.....................................\n",
      "[CV 4/5; 35/56] END ......neuron1=30, neuron2=8;, score=0.000 total time=  53.0s\n",
      "[CV 5/5; 35/56] START neuron1=30, neuron2=8.....................................\n",
      "[CV 5/5; 35/56] END ......neuron1=30, neuron2=8;, score=0.000 total time=  53.8s\n",
      "[CV 1/5; 36/56] START neuron1=30, neuron2=20....................................\n",
      "[CV 1/5; 36/56] END .....neuron1=30, neuron2=20;, score=0.000 total time=  55.0s\n",
      "[CV 2/5; 36/56] START neuron1=30, neuron2=20....................................\n",
      "[CV 2/5; 36/56] END .....neuron1=30, neuron2=20;, score=0.000 total time=  54.8s\n",
      "[CV 3/5; 36/56] START neuron1=30, neuron2=20....................................\n",
      "[CV 3/5; 36/56] END .....neuron1=30, neuron2=20;, score=0.000 total time=  54.9s\n",
      "[CV 4/5; 36/56] START neuron1=30, neuron2=20....................................\n",
      "[CV 4/5; 36/56] END .....neuron1=30, neuron2=20;, score=0.000 total time= 1.4min\n",
      "[CV 5/5; 36/56] START neuron1=30, neuron2=20....................................\n",
      "[CV 5/5; 36/56] END .....neuron1=30, neuron2=20;, score=0.000 total time=  43.0s\n",
      "[CV 1/5; 37/56] START neuron1=30, neuron2=30....................................\n",
      "[CV 1/5; 37/56] END .....neuron1=30, neuron2=30;, score=0.000 total time= 1.5min\n",
      "[CV 2/5; 37/56] START neuron1=30, neuron2=30....................................\n",
      "[CV 2/5; 37/56] END .....neuron1=30, neuron2=30;, score=0.000 total time= 1.6min\n",
      "[CV 3/5; 37/56] START neuron1=30, neuron2=30....................................\n",
      "[CV 3/5; 37/56] END .....neuron1=30, neuron2=30;, score=0.000 total time=  53.9s\n",
      "[CV 4/5; 37/56] START neuron1=30, neuron2=30....................................\n",
      "[CV 4/5; 37/56] END .....neuron1=30, neuron2=30;, score=0.000 total time=  53.7s\n",
      "[CV 5/5; 37/56] START neuron1=30, neuron2=30....................................\n",
      "[CV 5/5; 37/56] END .....neuron1=30, neuron2=30;, score=0.000 total time= 1.4min\n",
      "[CV 1/5; 38/56] START neuron1=30, neuron2=40....................................\n",
      "[CV 1/5; 38/56] END .....neuron1=30, neuron2=40;, score=0.000 total time=  49.9s\n",
      "[CV 2/5; 38/56] START neuron1=30, neuron2=40....................................\n",
      "[CV 2/5; 38/56] END .....neuron1=30, neuron2=40;, score=0.000 total time=  54.4s\n",
      "[CV 3/5; 38/56] START neuron1=30, neuron2=40....................................\n",
      "[CV 3/5; 38/56] END .....neuron1=30, neuron2=40;, score=0.000 total time=  57.2s\n",
      "[CV 4/5; 38/56] START neuron1=30, neuron2=40....................................\n",
      "[CV 4/5; 38/56] END .....neuron1=30, neuron2=40;, score=0.000 total time=  54.5s\n",
      "[CV 5/5; 38/56] START neuron1=30, neuron2=40....................................\n",
      "[CV 5/5; 38/56] END .....neuron1=30, neuron2=40;, score=0.000 total time= 1.2min\n",
      "[CV 1/5; 39/56] START neuron1=30, neuron2=50....................................\n",
      "[CV 1/5; 39/56] END .....neuron1=30, neuron2=50;, score=0.000 total time=  59.0s\n",
      "[CV 2/5; 39/56] START neuron1=30, neuron2=50....................................\n",
      "[CV 2/5; 39/56] END .....neuron1=30, neuron2=50;, score=0.000 total time=  53.6s\n",
      "[CV 3/5; 39/56] START neuron1=30, neuron2=50....................................\n",
      "[CV 3/5; 39/56] END .....neuron1=30, neuron2=50;, score=0.000 total time=  52.3s\n",
      "[CV 4/5; 39/56] START neuron1=30, neuron2=50....................................\n",
      "[CV 4/5; 39/56] END .....neuron1=30, neuron2=50;, score=0.000 total time=  52.0s\n",
      "[CV 5/5; 39/56] START neuron1=30, neuron2=50....................................\n",
      "[CV 5/5; 39/56] END .....neuron1=30, neuron2=50;, score=0.000 total time=  59.6s\n",
      "[CV 1/5; 40/56] START neuron1=30, neuron2=60....................................\n",
      "[CV 1/5; 40/56] END .....neuron1=30, neuron2=60;, score=0.000 total time=  55.7s\n",
      "[CV 2/5; 40/56] START neuron1=30, neuron2=60....................................\n",
      "[CV 2/5; 40/56] END .....neuron1=30, neuron2=60;, score=0.000 total time= 1.0min\n",
      "[CV 3/5; 40/56] START neuron1=30, neuron2=60....................................\n",
      "[CV 3/5; 40/56] END .....neuron1=30, neuron2=60;, score=0.000 total time= 1.1min\n",
      "[CV 4/5; 40/56] START neuron1=30, neuron2=60....................................\n",
      "[CV 4/5; 40/56] END .....neuron1=30, neuron2=60;, score=0.000 total time= 1.0min\n",
      "[CV 5/5; 40/56] START neuron1=30, neuron2=60....................................\n",
      "[CV 5/5; 40/56] END .....neuron1=30, neuron2=60;, score=0.000 total time= 1.0min\n",
      "[CV 1/5; 41/56] START neuron1=40, neuron2=2.....................................\n",
      "[CV 1/5; 41/56] END ......neuron1=40, neuron2=2;, score=0.000 total time= 1.0min\n",
      "[CV 2/5; 41/56] START neuron1=40, neuron2=2.....................................\n",
      "[CV 2/5; 41/56] END ......neuron1=40, neuron2=2;, score=0.000 total time=  58.6s\n",
      "[CV 3/5; 41/56] START neuron1=40, neuron2=2.....................................\n",
      "[CV 3/5; 41/56] END ......neuron1=40, neuron2=2;, score=0.000 total time=  53.7s\n",
      "[CV 4/5; 41/56] START neuron1=40, neuron2=2.....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 41/56] END ......neuron1=40, neuron2=2;, score=0.000 total time=  53.1s\n",
      "[CV 5/5; 41/56] START neuron1=40, neuron2=2.....................................\n",
      "[CV 5/5; 41/56] END ......neuron1=40, neuron2=2;, score=0.000 total time= 1.4min\n",
      "[CV 1/5; 42/56] START neuron1=40, neuron2=4.....................................\n",
      "[CV 1/5; 42/56] END ......neuron1=40, neuron2=4;, score=0.000 total time=  45.1s\n",
      "[CV 2/5; 42/56] START neuron1=40, neuron2=4.....................................\n",
      "[CV 2/5; 42/56] END ......neuron1=40, neuron2=4;, score=0.000 total time= 1.1min\n",
      "[CV 3/5; 42/56] START neuron1=40, neuron2=4.....................................\n",
      "[CV 3/5; 42/56] END ......neuron1=40, neuron2=4;, score=0.000 total time=  51.9s\n",
      "[CV 4/5; 42/56] START neuron1=40, neuron2=4.....................................\n",
      "[CV 4/5; 42/56] END ......neuron1=40, neuron2=4;, score=0.000 total time=  52.9s\n",
      "[CV 5/5; 42/56] START neuron1=40, neuron2=4.....................................\n",
      "[CV 5/5; 42/56] END ......neuron1=40, neuron2=4;, score=0.000 total time= 1.5min\n",
      "[CV 1/5; 43/56] START neuron1=40, neuron2=8.....................................\n",
      "[CV 1/5; 43/56] END ......neuron1=40, neuron2=8;, score=0.000 total time= 1.1min\n",
      "[CV 2/5; 43/56] START neuron1=40, neuron2=8.....................................\n",
      "[CV 2/5; 43/56] END ......neuron1=40, neuron2=8;, score=0.000 total time=  59.0s\n",
      "[CV 3/5; 43/56] START neuron1=40, neuron2=8.....................................\n",
      "[CV 3/5; 43/56] END ......neuron1=40, neuron2=8;, score=0.000 total time=  55.4s\n",
      "[CV 4/5; 43/56] START neuron1=40, neuron2=8.....................................\n",
      "[CV 4/5; 43/56] END ......neuron1=40, neuron2=8;, score=0.000 total time= 1.4min\n",
      "[CV 5/5; 43/56] START neuron1=40, neuron2=8.....................................\n",
      "[CV 5/5; 43/56] END ......neuron1=40, neuron2=8;, score=0.000 total time= 1.5min\n",
      "[CV 1/5; 44/56] START neuron1=40, neuron2=20....................................\n",
      "[CV 1/5; 44/56] END .....neuron1=40, neuron2=20;, score=0.000 total time= 1.2min\n",
      "[CV 2/5; 44/56] START neuron1=40, neuron2=20....................................\n",
      "[CV 2/5; 44/56] END .....neuron1=40, neuron2=20;, score=0.000 total time= 1.5min\n",
      "[CV 3/5; 44/56] START neuron1=40, neuron2=20....................................\n",
      "[CV 3/5; 44/56] END .....neuron1=40, neuron2=20;, score=0.000 total time= 1.3min\n",
      "[CV 4/5; 44/56] START neuron1=40, neuron2=20....................................\n",
      "[CV 4/5; 44/56] END .....neuron1=40, neuron2=20;, score=0.000 total time= 1.2min\n",
      "[CV 5/5; 44/56] START neuron1=40, neuron2=20....................................\n",
      "[CV 5/5; 44/56] END .....neuron1=40, neuron2=20;, score=0.000 total time= 1.2min\n",
      "[CV 1/5; 45/56] START neuron1=40, neuron2=30....................................\n",
      "[CV 1/5; 45/56] END .....neuron1=40, neuron2=30;, score=0.000 total time= 1.2min\n",
      "[CV 2/5; 45/56] START neuron1=40, neuron2=30....................................\n",
      "[CV 2/5; 45/56] END .....neuron1=40, neuron2=30;, score=0.000 total time= 1.2min\n",
      "[CV 3/5; 45/56] START neuron1=40, neuron2=30....................................\n",
      "[CV 3/5; 45/56] END .....neuron1=40, neuron2=30;, score=0.000 total time= 1.2min\n",
      "[CV 4/5; 45/56] START neuron1=40, neuron2=30....................................\n",
      "[CV 4/5; 45/56] END .....neuron1=40, neuron2=30;, score=0.000 total time= 1.3min\n",
      "[CV 5/5; 45/56] START neuron1=40, neuron2=30....................................\n",
      "[CV 5/5; 45/56] END .....neuron1=40, neuron2=30;, score=0.000 total time= 1.2min\n",
      "[CV 1/5; 46/56] START neuron1=40, neuron2=40....................................\n",
      "[CV 1/5; 46/56] END .....neuron1=40, neuron2=40;, score=0.000 total time= 1.2min\n",
      "[CV 2/5; 46/56] START neuron1=40, neuron2=40....................................\n",
      "[CV 2/5; 46/56] END .....neuron1=40, neuron2=40;, score=0.000 total time= 1.2min\n",
      "[CV 3/5; 46/56] START neuron1=40, neuron2=40....................................\n",
      "[CV 3/5; 46/56] END .....neuron1=40, neuron2=40;, score=0.000 total time= 1.2min\n",
      "[CV 4/5; 46/56] START neuron1=40, neuron2=40....................................\n",
      "[CV 4/5; 46/56] END .....neuron1=40, neuron2=40;, score=0.000 total time= 1.2min\n",
      "[CV 5/5; 46/56] START neuron1=40, neuron2=40....................................\n",
      "[CV 5/5; 46/56] END .....neuron1=40, neuron2=40;, score=0.000 total time= 1.2min\n",
      "[CV 1/5; 47/56] START neuron1=40, neuron2=50....................................\n",
      "[CV 1/5; 47/56] END .....neuron1=40, neuron2=50;, score=0.000 total time= 1.3min\n",
      "[CV 2/5; 47/56] START neuron1=40, neuron2=50....................................\n",
      "[CV 2/5; 47/56] END .....neuron1=40, neuron2=50;, score=0.000 total time= 1.2min\n",
      "[CV 3/5; 47/56] START neuron1=40, neuron2=50....................................\n",
      "[CV 3/5; 47/56] END .....neuron1=40, neuron2=50;, score=0.000 total time= 1.2min\n",
      "[CV 4/5; 47/56] START neuron1=40, neuron2=50....................................\n",
      "[CV 4/5; 47/56] END .....neuron1=40, neuron2=50;, score=0.000 total time= 1.2min\n",
      "[CV 5/5; 47/56] START neuron1=40, neuron2=50....................................\n",
      "[CV 5/5; 47/56] END .....neuron1=40, neuron2=50;, score=0.000 total time= 1.3min\n",
      "[CV 1/5; 48/56] START neuron1=40, neuron2=60....................................\n",
      "[CV 1/5; 48/56] END .....neuron1=40, neuron2=60;, score=0.000 total time= 1.3min\n",
      "[CV 2/5; 48/56] START neuron1=40, neuron2=60....................................\n",
      "[CV 2/5; 48/56] END .....neuron1=40, neuron2=60;, score=0.000 total time= 1.3min\n",
      "[CV 3/5; 48/56] START neuron1=40, neuron2=60....................................\n",
      "[CV 3/5; 48/56] END .....neuron1=40, neuron2=60;, score=0.000 total time= 1.2min\n",
      "[CV 4/5; 48/56] START neuron1=40, neuron2=60....................................\n",
      "[CV 4/5; 48/56] END .....neuron1=40, neuron2=60;, score=0.000 total time= 1.2min\n",
      "[CV 5/5; 48/56] START neuron1=40, neuron2=60....................................\n",
      "[CV 5/5; 48/56] END .....neuron1=40, neuron2=60;, score=0.000 total time= 1.5min\n",
      "[CV 1/5; 49/56] START neuron1=50, neuron2=2.....................................\n",
      "[CV 1/5; 49/56] END ......neuron1=50, neuron2=2;, score=0.000 total time= 1.2min\n",
      "[CV 2/5; 49/56] START neuron1=50, neuron2=2.....................................\n",
      "[CV 2/5; 49/56] END ......neuron1=50, neuron2=2;, score=0.000 total time= 1.2min\n",
      "[CV 3/5; 49/56] START neuron1=50, neuron2=2.....................................\n",
      "[CV 3/5; 49/56] END ......neuron1=50, neuron2=2;, score=0.000 total time= 1.2min\n",
      "[CV 4/5; 49/56] START neuron1=50, neuron2=2.....................................\n",
      "[CV 4/5; 49/56] END ......neuron1=50, neuron2=2;, score=0.000 total time= 1.2min\n",
      "[CV 5/5; 49/56] START neuron1=50, neuron2=2.....................................\n",
      "[CV 5/5; 49/56] END ......neuron1=50, neuron2=2;, score=0.000 total time= 1.2min\n",
      "[CV 1/5; 50/56] START neuron1=50, neuron2=4.....................................\n",
      "[CV 1/5; 50/56] END ......neuron1=50, neuron2=4;, score=0.000 total time= 1.5min\n",
      "[CV 2/5; 50/56] START neuron1=50, neuron2=4.....................................\n",
      "[CV 2/5; 50/56] END ......neuron1=50, neuron2=4;, score=0.000 total time= 1.5min\n",
      "[CV 3/5; 50/56] START neuron1=50, neuron2=4.....................................\n",
      "[CV 3/5; 50/56] END ......neuron1=50, neuron2=4;, score=0.000 total time=  56.6s\n",
      "[CV 4/5; 50/56] START neuron1=50, neuron2=4.....................................\n",
      "[CV 4/5; 50/56] END ......neuron1=50, neuron2=4;, score=0.000 total time=  55.1s\n",
      "[CV 5/5; 50/56] START neuron1=50, neuron2=4.....................................\n",
      "[CV 5/5; 50/56] END ......neuron1=50, neuron2=4;, score=0.000 total time=  55.9s\n",
      "[CV 1/5; 51/56] START neuron1=50, neuron2=8.....................................\n",
      "[CV 1/5; 51/56] END ......neuron1=50, neuron2=8;, score=0.000 total time=  59.0s\n",
      "[CV 2/5; 51/56] START neuron1=50, neuron2=8.....................................\n",
      "[CV 2/5; 51/56] END ......neuron1=50, neuron2=8;, score=0.000 total time=  55.0s\n",
      "[CV 3/5; 51/56] START neuron1=50, neuron2=8.....................................\n",
      "[CV 3/5; 51/56] END ......neuron1=50, neuron2=8;, score=0.000 total time=  54.6s\n",
      "[CV 4/5; 51/56] START neuron1=50, neuron2=8.....................................\n",
      "[CV 4/5; 51/56] END ......neuron1=50, neuron2=8;, score=0.000 total time=  53.3s\n",
      "[CV 5/5; 51/56] START neuron1=50, neuron2=8.....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 51/56] END ......neuron1=50, neuron2=8;, score=0.000 total time=  55.2s\n",
      "[CV 1/5; 52/56] START neuron1=50, neuron2=20....................................\n",
      "[CV 1/5; 52/56] END .....neuron1=50, neuron2=20;, score=0.000 total time= 1.0min\n",
      "[CV 2/5; 52/56] START neuron1=50, neuron2=20....................................\n",
      "[CV 2/5; 52/56] END .....neuron1=50, neuron2=20;, score=0.000 total time=  54.9s\n",
      "[CV 3/5; 52/56] START neuron1=50, neuron2=20....................................\n",
      "[CV 3/5; 52/56] END .....neuron1=50, neuron2=20;, score=0.000 total time=  54.0s\n",
      "[CV 4/5; 52/56] START neuron1=50, neuron2=20....................................\n",
      "[CV 4/5; 52/56] END .....neuron1=50, neuron2=20;, score=0.000 total time=  52.4s\n",
      "[CV 5/5; 52/56] START neuron1=50, neuron2=20....................................\n",
      "[CV 5/5; 52/56] END .....neuron1=50, neuron2=20;, score=0.000 total time= 1.0min\n",
      "[CV 1/5; 53/56] START neuron1=50, neuron2=30....................................\n",
      "[CV 1/5; 53/56] END .....neuron1=50, neuron2=30;, score=0.000 total time= 1.2min\n",
      "[CV 2/5; 53/56] START neuron1=50, neuron2=30....................................\n",
      "[CV 2/5; 53/56] END .....neuron1=50, neuron2=30;, score=0.000 total time= 1.3min\n",
      "[CV 3/5; 53/56] START neuron1=50, neuron2=30....................................\n",
      "[CV 3/5; 53/56] END .....neuron1=50, neuron2=30;, score=0.000 total time= 4.6min\n",
      "[CV 4/5; 53/56] START neuron1=50, neuron2=30....................................\n",
      "[CV 4/5; 53/56] END .....neuron1=50, neuron2=30;, score=0.000 total time= 2.5min\n",
      "[CV 5/5; 53/56] START neuron1=50, neuron2=30....................................\n",
      "[CV 5/5; 53/56] END .....neuron1=50, neuron2=30;, score=0.000 total time= 1.3min\n",
      "[CV 1/5; 54/56] START neuron1=50, neuron2=40....................................\n",
      "[CV 1/5; 54/56] END .....neuron1=50, neuron2=40;, score=0.000 total time= 1.1min\n",
      "[CV 2/5; 54/56] START neuron1=50, neuron2=40....................................\n",
      "[CV 2/5; 54/56] END .....neuron1=50, neuron2=40;, score=0.000 total time=  54.2s\n",
      "[CV 3/5; 54/56] START neuron1=50, neuron2=40....................................\n",
      "[CV 3/5; 54/56] END .....neuron1=50, neuron2=40;, score=0.000 total time= 1.0min\n",
      "[CV 4/5; 54/56] START neuron1=50, neuron2=40....................................\n",
      "[CV 4/5; 54/56] END .....neuron1=50, neuron2=40;, score=0.000 total time=65.0min\n",
      "[CV 5/5; 54/56] START neuron1=50, neuron2=40....................................\n",
      "[CV 5/5; 54/56] END .....neuron1=50, neuron2=40;, score=0.000 total time=  34.5s\n",
      "[CV 1/5; 55/56] START neuron1=50, neuron2=50....................................\n",
      "[CV 1/5; 55/56] END .....neuron1=50, neuron2=50;, score=0.000 total time=  33.4s\n",
      "[CV 2/5; 55/56] START neuron1=50, neuron2=50....................................\n",
      "[CV 2/5; 55/56] END .....neuron1=50, neuron2=50;, score=0.000 total time=  35.2s\n",
      "[CV 3/5; 55/56] START neuron1=50, neuron2=50....................................\n",
      "[CV 3/5; 55/56] END .....neuron1=50, neuron2=50;, score=0.000 total time=  34.1s\n",
      "[CV 4/5; 55/56] START neuron1=50, neuron2=50....................................\n",
      "[CV 4/5; 55/56] END .....neuron1=50, neuron2=50;, score=0.000 total time=  33.5s\n",
      "[CV 5/5; 55/56] START neuron1=50, neuron2=50....................................\n",
      "[CV 5/5; 55/56] END .....neuron1=50, neuron2=50;, score=0.000 total time=  33.9s\n",
      "[CV 1/5; 56/56] START neuron1=50, neuron2=60....................................\n",
      "[CV 1/5; 56/56] END .....neuron1=50, neuron2=60;, score=0.000 total time=  34.1s\n",
      "[CV 2/5; 56/56] START neuron1=50, neuron2=60....................................\n",
      "[CV 2/5; 56/56] END .....neuron1=50, neuron2=60;, score=0.000 total time=  35.0s\n",
      "[CV 3/5; 56/56] START neuron1=50, neuron2=60....................................\n",
      "[CV 3/5; 56/56] END .....neuron1=50, neuron2=60;, score=0.000 total time=  34.4s\n",
      "[CV 4/5; 56/56] START neuron1=50, neuron2=60....................................\n",
      "[CV 4/5; 56/56] END .....neuron1=50, neuron2=60;, score=0.000 total time=  34.6s\n",
      "[CV 5/5; 56/56] START neuron1=50, neuron2=60....................................\n",
      "[CV 5/5; 56/56] END .....neuron1=50, neuron2=60;, score=0.000 total time=  43.8s\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 10,epochs = 10)\n",
    "\n",
    "neuron1 = [4,8,16,20,30,40,50]\n",
    "neuron2 = [2,4,8,20,30,40,50,60]\n",
    "\n",
    "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61fd3348",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T14:53:51.045368Z",
     "start_time": "2022-04-29T14:53:51.004364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.0, using {'neuron1': 4, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 20}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 30}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 40}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 50}\n",
      "0.0,0.0 with: {'neuron1': 4, 'neuron2': 60}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 20}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 30}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 40}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 50}\n",
      "0.0,0.0 with: {'neuron1': 8, 'neuron2': 60}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 20}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 30}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 40}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 50}\n",
      "0.0,0.0 with: {'neuron1': 16, 'neuron2': 60}\n",
      "0.0,0.0 with: {'neuron1': 20, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 20, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 20, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 20, 'neuron2': 20}\n",
      "0.0,0.0 with: {'neuron1': 20, 'neuron2': 30}\n",
      "0.0,0.0 with: {'neuron1': 20, 'neuron2': 40}\n",
      "0.0,0.0 with: {'neuron1': 20, 'neuron2': 50}\n",
      "0.0,0.0 with: {'neuron1': 20, 'neuron2': 60}\n",
      "0.0,0.0 with: {'neuron1': 30, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 30, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 30, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 30, 'neuron2': 20}\n",
      "0.0,0.0 with: {'neuron1': 30, 'neuron2': 30}\n",
      "0.0,0.0 with: {'neuron1': 30, 'neuron2': 40}\n",
      "0.0,0.0 with: {'neuron1': 30, 'neuron2': 50}\n",
      "0.0,0.0 with: {'neuron1': 30, 'neuron2': 60}\n",
      "0.0,0.0 with: {'neuron1': 40, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 40, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 40, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 40, 'neuron2': 20}\n",
      "0.0,0.0 with: {'neuron1': 40, 'neuron2': 30}\n",
      "0.0,0.0 with: {'neuron1': 40, 'neuron2': 40}\n",
      "0.0,0.0 with: {'neuron1': 40, 'neuron2': 50}\n",
      "0.0,0.0 with: {'neuron1': 40, 'neuron2': 60}\n",
      "0.0,0.0 with: {'neuron1': 50, 'neuron2': 2}\n",
      "0.0,0.0 with: {'neuron1': 50, 'neuron2': 4}\n",
      "0.0,0.0 with: {'neuron1': 50, 'neuron2': 8}\n",
      "0.0,0.0 with: {'neuron1': 50, 'neuron2': 20}\n",
      "0.0,0.0 with: {'neuron1': 50, 'neuron2': 30}\n",
      "0.0,0.0 with: {'neuron1': 50, 'neuron2': 40}\n",
      "0.0,0.0 with: {'neuron1': 50, 'neuron2': 50}\n",
      "0.0,0.0 with: {'neuron1': 50, 'neuron2': 60}\n"
     ]
    }
   ],
   "source": [
    "#Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95fa364c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T14:53:59.480222Z",
     "start_time": "2022-04-29T14:53:59.427204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10527, 10), (4512, 10), (10527,), (4512,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test =train_test_split(X,y,test_size =0.3,random_state =42)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7d32bee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T14:54:06.516856Z",
     "start_time": "2022-04-29T14:54:06.382821Z"
    }
   },
   "outputs": [],
   "source": [
    "optmizer =RMSprop(0.001)\n",
    "model_new=keras.Sequential([\n",
    "    keras.layers.Dense(4,input_dim =(n_features),activation='relu'),\n",
    "    keras.layers.Dense(2,activation ='relu')\n",
    "])\n",
    "model_new.compile(optimizer =optmizer,loss= 'mean_squared_error',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c219dae6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T14:55:08.258858Z",
     "start_time": "2022-04-29T14:54:11.342380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1053/1053 [==============================] - 8s 6ms/step - loss: 0.8120 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1053/1053 [==============================] - 6s 6ms/step - loss: 0.7366 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1053/1053 [==============================] - 6s 6ms/step - loss: 0.7355 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1053/1053 [==============================] - 5s 5ms/step - loss: 0.7353 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1053/1053 [==============================] - 5s 5ms/step - loss: 0.7352 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1053/1053 [==============================] - 5s 5ms/step - loss: 0.7352 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1053/1053 [==============================] - 6s 6ms/step - loss: 0.7351 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1053/1053 [==============================] - 5s 5ms/step - loss: 0.7351 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1053/1053 [==============================] - 5s 5ms/step - loss: 0.7351 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1053/1053 [==============================] - 5s 5ms/step - loss: 0.7351 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20bf7346580>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_value =42;\n",
    "import random\n",
    "tensorflow.random.set_seed(seed_value)\n",
    "model_new.fit(X_train, y_train, epochs=10, batch_size=10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f777e8b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T14:55:10.087431Z",
     "start_time": "2022-04-29T14:55:09.203076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 4ms/step - loss: 0.7501 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7501411437988281, 0.0]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc03f3c2",
   "metadata": {},
   "source": [
    "# Neural Network(Forest Fire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0e1fc77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T14:59:04.833376Z",
     "start_time": "2022-04-29T14:59:03.520523Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Layer,Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0d1be68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T14:59:35.971146Z",
     "start_time": "2022-04-29T14:59:35.907130Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\mrmri\\Downloads\\Assignments_Excelr\\Neural_Networks\\forestfires.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "226017f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T14:59:47.238416Z",
     "start_time": "2022-04-29T14:59:47.112385Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "0           0          small  \n",
       "1           0          small  \n",
       "2           0          small  \n",
       "3           0          small  \n",
       "4           0          small  \n",
       "..        ...            ...  \n",
       "512         0          large  \n",
       "513         0          large  \n",
       "514         0          large  \n",
       "515         0          small  \n",
       "516         0          small  \n",
       "\n",
       "[517 rows x 31 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b0ed04f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T15:00:02.373602Z",
     "start_time": "2022-04-29T15:00:02.310585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 31 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   month          517 non-null    object \n",
      " 1   day            517 non-null    object \n",
      " 2   FFMC           517 non-null    float64\n",
      " 3   DMC            517 non-null    float64\n",
      " 4   DC             517 non-null    float64\n",
      " 5   ISI            517 non-null    float64\n",
      " 6   temp           517 non-null    float64\n",
      " 7   RH             517 non-null    int64  \n",
      " 8   wind           517 non-null    float64\n",
      " 9   rain           517 non-null    float64\n",
      " 10  area           517 non-null    float64\n",
      " 11  dayfri         517 non-null    int64  \n",
      " 12  daymon         517 non-null    int64  \n",
      " 13  daysat         517 non-null    int64  \n",
      " 14  daysun         517 non-null    int64  \n",
      " 15  daythu         517 non-null    int64  \n",
      " 16  daytue         517 non-null    int64  \n",
      " 17  daywed         517 non-null    int64  \n",
      " 18  monthapr       517 non-null    int64  \n",
      " 19  monthaug       517 non-null    int64  \n",
      " 20  monthdec       517 non-null    int64  \n",
      " 21  monthfeb       517 non-null    int64  \n",
      " 22  monthjan       517 non-null    int64  \n",
      " 23  monthjul       517 non-null    int64  \n",
      " 24  monthjun       517 non-null    int64  \n",
      " 25  monthmar       517 non-null    int64  \n",
      " 26  monthmay       517 non-null    int64  \n",
      " 27  monthnov       517 non-null    int64  \n",
      " 28  monthoct       517 non-null    int64  \n",
      " 29  monthsep       517 non-null    int64  \n",
      " 30  size_category  517 non-null    object \n",
      "dtypes: float64(8), int64(20), object(3)\n",
      "memory usage: 125.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae5abf02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T15:00:12.924088Z",
     "start_time": "2022-04-29T15:00:12.873073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.05959472e-01, -1.32332557e+00, -1.83047676e+00, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.17954077e+00,  4.88890915e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.04982188e+00,  5.60715454e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       ...,\n",
       "       [-1.64008316e+00, -8.46647711e-01,  4.74768113e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [ 6.80956663e-01,  5.49002541e-01,  2.69382214e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-2.02087875e+00, -1.68591332e+00, -1.78044169e+00, ...,\n",
       "         2.27156334e+01, -1.72859706e-01, -7.06081245e-01]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1= df.iloc[:,2:30]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "sc.fit(df1)\n",
    "df_norm = sc.transform(df1)\n",
    "df_norm                     #Normalised dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "35b44c21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T15:00:23.007268Z",
     "start_time": "2022-04-29T15:00:22.014031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.76670947e+00, -1.32025451e+00, -8.43971398e-01, ...,\n",
       "        -6.53345819e-02,  6.76594676e-15, -3.95512041e-15],\n",
       "       [ 3.90786263e-01,  8.31061522e-01, -1.10136513e+00, ...,\n",
       "         3.42618601e-02,  8.94175491e-15, -1.87431395e-15],\n",
       "       [ 6.90415596e-01,  1.17774562e+00, -1.22199841e+00, ...,\n",
       "         2.63235187e-02,  1.76638742e-15, -1.25252498e-15],\n",
       "       ...,\n",
       "       [ 9.21634000e-01, -2.64543072e-01,  2.71921606e+00, ...,\n",
       "        -2.97865814e-01, -2.65989591e-16, -4.70561644e-16],\n",
       "       [-1.62054896e+00, -9.78838231e-01,  3.31987355e-01, ...,\n",
       "         3.91949863e-02, -5.13927944e-18,  1.15865204e-16],\n",
       "       [ 4.07590654e+00, -3.67440726e-01, -2.47151775e-01, ...,\n",
       "        -2.50420726e-02,  5.67138903e-17,  6.43487148e-17]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 28)\n",
    "pca_values = pca.fit_transform(df_norm)\n",
    "pca_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6876422d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T15:00:32.519882Z",
     "start_time": "2022-04-29T15:00:32.502874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.35522746e-01, 6.85788793e-02, 6.23572652e-02, 5.32713255e-02,\n",
       "       4.75942360e-02, 4.68009902e-02, 4.37490015e-02, 4.28025164e-02,\n",
       "       4.08875728e-02, 4.01633268e-02, 3.92926854e-02, 3.83232321e-02,\n",
       "       3.64221503e-02, 3.63217289e-02, 3.57856782e-02, 3.50087806e-02,\n",
       "       3.35447704e-02, 3.24777366e-02, 3.04490902e-02, 3.00246758e-02,\n",
       "       2.37167400e-02, 2.08329788e-02, 1.18357869e-02, 8.88449559e-03,\n",
       "       4.55347471e-03, 7.98135931e-04, 2.67271490e-32, 1.03110502e-32])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = pca.explained_variance_ratio_\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "628c7108",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T15:00:40.051450Z",
     "start_time": "2022-04-29T15:00:40.017446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.55, 20.41, 26.65, 31.98, 36.74, 41.42, 45.79, 50.07, 54.16,\n",
       "       58.18, 62.11, 65.94, 69.58, 73.21, 76.79, 80.29, 83.64, 86.89,\n",
       "       89.93, 92.93, 95.3 , 97.38, 98.56, 99.45, 99.91, 99.99, 99.99,\n",
       "       99.99])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1 = np.cumsum(np.round(var,decimals = 4)*100)\n",
    "var1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "daeda9c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T15:00:47.964888Z",
     "start_time": "2022-04-29T15:00:46.448460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(var1,color=\"red\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89f8107d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T15:00:57.959830Z",
     "start_time": "2022-04-29T15:00:57.807793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>pc4</th>\n",
       "      <th>pc5</th>\n",
       "      <th>pc6</th>\n",
       "      <th>pc7</th>\n",
       "      <th>pc8</th>\n",
       "      <th>pc9</th>\n",
       "      <th>pc10</th>\n",
       "      <th>...</th>\n",
       "      <th>pc16</th>\n",
       "      <th>pc17</th>\n",
       "      <th>pc18</th>\n",
       "      <th>pc19</th>\n",
       "      <th>pc20</th>\n",
       "      <th>pc21</th>\n",
       "      <th>pc22</th>\n",
       "      <th>pc23</th>\n",
       "      <th>pc24</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.766709</td>\n",
       "      <td>-1.320255</td>\n",
       "      <td>-0.843971</td>\n",
       "      <td>-1.994738</td>\n",
       "      <td>-1.453359</td>\n",
       "      <td>0.693985</td>\n",
       "      <td>0.308104</td>\n",
       "      <td>-0.019764</td>\n",
       "      <td>0.010161</td>\n",
       "      <td>-0.437314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197543</td>\n",
       "      <td>-0.021839</td>\n",
       "      <td>0.688958</td>\n",
       "      <td>0.563603</td>\n",
       "      <td>-0.439596</td>\n",
       "      <td>-0.926619</td>\n",
       "      <td>-0.405425</td>\n",
       "      <td>-0.118719</td>\n",
       "      <td>-0.017933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.390786</td>\n",
       "      <td>0.831062</td>\n",
       "      <td>-1.101365</td>\n",
       "      <td>1.400671</td>\n",
       "      <td>2.869388</td>\n",
       "      <td>0.965898</td>\n",
       "      <td>-2.795574</td>\n",
       "      <td>0.041095</td>\n",
       "      <td>-0.548879</td>\n",
       "      <td>0.104500</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.503167</td>\n",
       "      <td>0.499649</td>\n",
       "      <td>0.563706</td>\n",
       "      <td>-0.703319</td>\n",
       "      <td>-1.535718</td>\n",
       "      <td>-0.892995</td>\n",
       "      <td>0.836590</td>\n",
       "      <td>0.204975</td>\n",
       "      <td>0.290771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.690416</td>\n",
       "      <td>1.177746</td>\n",
       "      <td>-1.221998</td>\n",
       "      <td>2.442038</td>\n",
       "      <td>1.090630</td>\n",
       "      <td>0.390801</td>\n",
       "      <td>-1.586675</td>\n",
       "      <td>-2.159336</td>\n",
       "      <td>-0.090580</td>\n",
       "      <td>0.260888</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.545144</td>\n",
       "      <td>-0.658411</td>\n",
       "      <td>-0.423618</td>\n",
       "      <td>0.860550</td>\n",
       "      <td>-1.195230</td>\n",
       "      <td>-0.297870</td>\n",
       "      <td>0.743648</td>\n",
       "      <td>0.081757</td>\n",
       "      <td>0.345915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.359951</td>\n",
       "      <td>-1.161443</td>\n",
       "      <td>0.385728</td>\n",
       "      <td>-2.118328</td>\n",
       "      <td>-1.949601</td>\n",
       "      <td>1.027664</td>\n",
       "      <td>-0.179422</td>\n",
       "      <td>-0.250227</td>\n",
       "      <td>-0.620329</td>\n",
       "      <td>-1.343189</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040887</td>\n",
       "      <td>0.017843</td>\n",
       "      <td>0.332572</td>\n",
       "      <td>1.164745</td>\n",
       "      <td>-1.632741</td>\n",
       "      <td>-0.817618</td>\n",
       "      <td>1.523710</td>\n",
       "      <td>-0.342302</td>\n",
       "      <td>-0.378420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.974329</td>\n",
       "      <td>-0.842626</td>\n",
       "      <td>1.327788</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>-1.124763</td>\n",
       "      <td>-0.574676</td>\n",
       "      <td>-0.777155</td>\n",
       "      <td>0.303635</td>\n",
       "      <td>0.861126</td>\n",
       "      <td>-2.024719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844431</td>\n",
       "      <td>1.014944</td>\n",
       "      <td>-0.618231</td>\n",
       "      <td>0.822853</td>\n",
       "      <td>-1.794109</td>\n",
       "      <td>-0.723371</td>\n",
       "      <td>2.020419</td>\n",
       "      <td>-0.545591</td>\n",
       "      <td>0.161735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>-0.087560</td>\n",
       "      <td>0.153964</td>\n",
       "      <td>1.241810</td>\n",
       "      <td>1.536581</td>\n",
       "      <td>0.372425</td>\n",
       "      <td>-1.133422</td>\n",
       "      <td>-0.362287</td>\n",
       "      <td>0.766946</td>\n",
       "      <td>0.818745</td>\n",
       "      <td>-0.289632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300522</td>\n",
       "      <td>0.513876</td>\n",
       "      <td>0.539642</td>\n",
       "      <td>-0.052958</td>\n",
       "      <td>1.898628</td>\n",
       "      <td>-1.441786</td>\n",
       "      <td>-0.821192</td>\n",
       "      <td>-1.205707</td>\n",
       "      <td>-0.698666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0.794366</td>\n",
       "      <td>-0.083966</td>\n",
       "      <td>2.670485</td>\n",
       "      <td>0.284995</td>\n",
       "      <td>0.223323</td>\n",
       "      <td>-0.904232</td>\n",
       "      <td>-0.014849</td>\n",
       "      <td>0.107226</td>\n",
       "      <td>1.340049</td>\n",
       "      <td>-0.147246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342367</td>\n",
       "      <td>0.485571</td>\n",
       "      <td>0.580150</td>\n",
       "      <td>0.384984</td>\n",
       "      <td>0.086251</td>\n",
       "      <td>-0.970693</td>\n",
       "      <td>-1.353365</td>\n",
       "      <td>-1.254890</td>\n",
       "      <td>-1.212175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.921634</td>\n",
       "      <td>-0.264543</td>\n",
       "      <td>2.719216</td>\n",
       "      <td>-0.019643</td>\n",
       "      <td>0.242195</td>\n",
       "      <td>-0.966939</td>\n",
       "      <td>-0.118080</td>\n",
       "      <td>0.123010</td>\n",
       "      <td>1.290364</td>\n",
       "      <td>-0.177553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332816</td>\n",
       "      <td>0.344047</td>\n",
       "      <td>0.122409</td>\n",
       "      <td>0.313948</td>\n",
       "      <td>0.211157</td>\n",
       "      <td>-0.777731</td>\n",
       "      <td>-1.736711</td>\n",
       "      <td>-1.154127</td>\n",
       "      <td>-1.230040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>-1.620549</td>\n",
       "      <td>-0.978838</td>\n",
       "      <td>0.331987</td>\n",
       "      <td>1.256638</td>\n",
       "      <td>-0.408164</td>\n",
       "      <td>0.735698</td>\n",
       "      <td>0.815510</td>\n",
       "      <td>-1.398344</td>\n",
       "      <td>0.076379</td>\n",
       "      <td>-0.005814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011739</td>\n",
       "      <td>-1.035533</td>\n",
       "      <td>-0.774382</td>\n",
       "      <td>-0.216315</td>\n",
       "      <td>0.515791</td>\n",
       "      <td>0.080575</td>\n",
       "      <td>-0.055548</td>\n",
       "      <td>-0.067502</td>\n",
       "      <td>-0.311027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>4.075907</td>\n",
       "      <td>-0.367441</td>\n",
       "      <td>-0.247152</td>\n",
       "      <td>0.979966</td>\n",
       "      <td>6.792273</td>\n",
       "      <td>5.943666</td>\n",
       "      <td>-1.639583</td>\n",
       "      <td>8.121827</td>\n",
       "      <td>-0.627980</td>\n",
       "      <td>4.953722</td>\n",
       "      <td>...</td>\n",
       "      <td>10.467443</td>\n",
       "      <td>-7.333036</td>\n",
       "      <td>0.377340</td>\n",
       "      <td>8.870354</td>\n",
       "      <td>-1.074288</td>\n",
       "      <td>2.382433</td>\n",
       "      <td>1.042850</td>\n",
       "      <td>0.296436</td>\n",
       "      <td>0.125099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pc1       pc2       pc3       pc4       pc5       pc6       pc7  \\\n",
       "0    3.766709 -1.320255 -0.843971 -1.994738 -1.453359  0.693985  0.308104   \n",
       "1    0.390786  0.831062 -1.101365  1.400671  2.869388  0.965898 -2.795574   \n",
       "2    0.690416  1.177746 -1.221998  2.442038  1.090630  0.390801 -1.586675   \n",
       "3    3.359951 -1.161443  0.385728 -2.118328 -1.949601  1.027664 -0.179422   \n",
       "4    2.974329 -0.842626  1.327788  0.038086 -1.124763 -0.574676 -0.777155   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512 -0.087560  0.153964  1.241810  1.536581  0.372425 -1.133422 -0.362287   \n",
       "513  0.794366 -0.083966  2.670485  0.284995  0.223323 -0.904232 -0.014849   \n",
       "514  0.921634 -0.264543  2.719216 -0.019643  0.242195 -0.966939 -0.118080   \n",
       "515 -1.620549 -0.978838  0.331987  1.256638 -0.408164  0.735698  0.815510   \n",
       "516  4.075907 -0.367441 -0.247152  0.979966  6.792273  5.943666 -1.639583   \n",
       "\n",
       "          pc8       pc9      pc10  ...       pc16      pc17      pc18  \\\n",
       "0   -0.019764  0.010161 -0.437314  ...  -0.197543 -0.021839  0.688958   \n",
       "1    0.041095 -0.548879  0.104500  ...  -2.503167  0.499649  0.563706   \n",
       "2   -2.159336 -0.090580  0.260888  ...  -2.545144 -0.658411 -0.423618   \n",
       "3   -0.250227 -0.620329 -1.343189  ...  -0.040887  0.017843  0.332572   \n",
       "4    0.303635  0.861126 -2.024719  ...   0.844431  1.014944 -0.618231   \n",
       "..        ...       ...       ...  ...        ...       ...       ...   \n",
       "512  0.766946  0.818745 -0.289632  ...   0.300522  0.513876  0.539642   \n",
       "513  0.107226  1.340049 -0.147246  ...   0.342367  0.485571  0.580150   \n",
       "514  0.123010  1.290364 -0.177553  ...   0.332816  0.344047  0.122409   \n",
       "515 -1.398344  0.076379 -0.005814  ...  -0.011739 -1.035533 -0.774382   \n",
       "516  8.121827 -0.627980  4.953722  ...  10.467443 -7.333036  0.377340   \n",
       "\n",
       "         pc19      pc20      pc21      pc22      pc23      pc24  size_category  \n",
       "0    0.563603 -0.439596 -0.926619 -0.405425 -0.118719 -0.017933              0  \n",
       "1   -0.703319 -1.535718 -0.892995  0.836590  0.204975  0.290771              0  \n",
       "2    0.860550 -1.195230 -0.297870  0.743648  0.081757  0.345915              0  \n",
       "3    1.164745 -1.632741 -0.817618  1.523710 -0.342302 -0.378420              0  \n",
       "4    0.822853 -1.794109 -0.723371  2.020419 -0.545591  0.161735              0  \n",
       "..        ...       ...       ...       ...       ...       ...            ...  \n",
       "512 -0.052958  1.898628 -1.441786 -0.821192 -1.205707 -0.698666              1  \n",
       "513  0.384984  0.086251 -0.970693 -1.353365 -1.254890 -1.212175              1  \n",
       "514  0.313948  0.211157 -0.777731 -1.736711 -1.154127 -1.230040              1  \n",
       "515 -0.216315  0.515791  0.080575 -0.055548 -0.067502 -0.311027              0  \n",
       "516  8.870354 -1.074288  2.382433  1.042850  0.296436  0.125099              0  \n",
       "\n",
       "[517 rows x 25 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalDf = pd.concat([pd.DataFrame(pca_values[:,0:24],columns=['pc1','pc2','pc3','pc4','pc5','pc6','pc7',\n",
    "                                                             'pc8','pc9','pc10','pc11','pc12','pc13','pc14',\n",
    "                                                             'pc15','pc16','pc17','pc18','pc19','pc20','pc21',\n",
    "                                                             'pc22','pc23','pc24']),\n",
    "                     df[['size_category']]], axis = 1)\n",
    "finalDf.size_category.replace(('large','small'),(1,0),inplace=True)\n",
    "finalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "004f3c94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T15:01:06.563998Z",
     "start_time": "2022-04-29T15:01:06.488981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = finalDf.values\n",
    "X = array[:,0:24]\n",
    "Y = array[:,24]\n",
    "\n",
    "X.reshape(-1,1)\n",
    "Y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "109ba6c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T15:01:23.350570Z",
     "start_time": "2022-04-29T15:01:23.202538Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=24, activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7278b662",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T15:01:29.384718Z",
     "start_time": "2022-04-29T15:01:29.346716Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e79f3b48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T15:03:02.540162Z",
     "start_time": "2022-04-29T15:01:35.379626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "37/37 [==============================] - 6s 64ms/step - loss: 0.6316 - accuracy: 0.6981 - val_loss: 0.6518 - val_accuracy: 0.6410\n",
      "Epoch 2/150\n",
      "37/37 [==============================] - 2s 42ms/step - loss: 0.5891 - accuracy: 0.7452 - val_loss: 0.6596 - val_accuracy: 0.6538\n",
      "Epoch 3/150\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.5607 - accuracy: 0.7535 - val_loss: 0.6647 - val_accuracy: 0.6538\n",
      "Epoch 4/150\n",
      "37/37 [==============================] - 1s 33ms/step - loss: 0.5398 - accuracy: 0.7590 - val_loss: 0.6688 - val_accuracy: 0.6795\n",
      "Epoch 5/150\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.5226 - accuracy: 0.7590 - val_loss: 0.6726 - val_accuracy: 0.6795\n",
      "Epoch 6/150\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.5096 - accuracy: 0.7618 - val_loss: 0.6740 - val_accuracy: 0.6795\n",
      "Epoch 7/150\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 0.4996 - accuracy: 0.7729 - val_loss: 0.6721 - val_accuracy: 0.6859\n",
      "Epoch 8/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.4918 - accuracy: 0.7784 - val_loss: 0.6724 - val_accuracy: 0.6859\n",
      "Epoch 9/150\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.4820 - accuracy: 0.7784 - val_loss: 0.6753 - val_accuracy: 0.6859\n",
      "Epoch 10/150\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.4756 - accuracy: 0.7839 - val_loss: 0.6696 - val_accuracy: 0.6859\n",
      "Epoch 11/150\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.4691 - accuracy: 0.7839 - val_loss: 0.6727 - val_accuracy: 0.6859\n",
      "Epoch 12/150\n",
      "37/37 [==============================] - 1s 28ms/step - loss: 0.4637 - accuracy: 0.7895 - val_loss: 0.6745 - val_accuracy: 0.6923\n",
      "Epoch 13/150\n",
      "37/37 [==============================] - 1s 12ms/step - loss: 0.4569 - accuracy: 0.7978 - val_loss: 0.6681 - val_accuracy: 0.6923\n",
      "Epoch 14/150\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.4491 - accuracy: 0.7950 - val_loss: 0.6743 - val_accuracy: 0.6923\n",
      "Epoch 15/150\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.4427 - accuracy: 0.7950 - val_loss: 0.6716 - val_accuracy: 0.6923\n",
      "Epoch 16/150\n",
      "37/37 [==============================] - 2s 42ms/step - loss: 0.4364 - accuracy: 0.7978 - val_loss: 0.6694 - val_accuracy: 0.6923\n",
      "Epoch 17/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.4299 - accuracy: 0.8089 - val_loss: 0.6635 - val_accuracy: 0.6987\n",
      "Epoch 18/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.4235 - accuracy: 0.8116 - val_loss: 0.6645 - val_accuracy: 0.6987\n",
      "Epoch 19/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.4181 - accuracy: 0.8116 - val_loss: 0.6641 - val_accuracy: 0.6987\n",
      "Epoch 20/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.4128 - accuracy: 0.8172 - val_loss: 0.6712 - val_accuracy: 0.6987\n",
      "Epoch 21/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.4054 - accuracy: 0.8172 - val_loss: 0.6637 - val_accuracy: 0.6923\n",
      "Epoch 22/150\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.3998 - accuracy: 0.8172 - val_loss: 0.6588 - val_accuracy: 0.6859\n",
      "Epoch 23/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.3918 - accuracy: 0.8227 - val_loss: 0.6585 - val_accuracy: 0.6859\n",
      "Epoch 24/150\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.3841 - accuracy: 0.8227 - val_loss: 0.6590 - val_accuracy: 0.7051\n",
      "Epoch 25/150\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.3788 - accuracy: 0.8283 - val_loss: 0.6489 - val_accuracy: 0.7179\n",
      "Epoch 26/150\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.3704 - accuracy: 0.8310 - val_loss: 0.6490 - val_accuracy: 0.7179\n",
      "Epoch 27/150\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.3627 - accuracy: 0.8338 - val_loss: 0.6473 - val_accuracy: 0.7115\n",
      "Epoch 28/150\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.3558 - accuracy: 0.8366 - val_loss: 0.6483 - val_accuracy: 0.7115\n",
      "Epoch 29/150\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.3492 - accuracy: 0.8338 - val_loss: 0.6468 - val_accuracy: 0.7179\n",
      "Epoch 30/150\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.3412 - accuracy: 0.8393 - val_loss: 0.6450 - val_accuracy: 0.7372\n",
      "Epoch 31/150\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.3338 - accuracy: 0.8449 - val_loss: 0.6436 - val_accuracy: 0.7436\n",
      "Epoch 32/150\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.3281 - accuracy: 0.8560 - val_loss: 0.6512 - val_accuracy: 0.7436\n",
      "Epoch 33/150\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.3242 - accuracy: 0.8532 - val_loss: 0.6558 - val_accuracy: 0.7436\n",
      "Epoch 34/150\n",
      "37/37 [==============================] - 1s 40ms/step - loss: 0.3188 - accuracy: 0.8643 - val_loss: 0.6528 - val_accuracy: 0.7372\n",
      "Epoch 35/150\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.3115 - accuracy: 0.8670 - val_loss: 0.6567 - val_accuracy: 0.7308\n",
      "Epoch 36/150\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.3043 - accuracy: 0.8698 - val_loss: 0.6599 - val_accuracy: 0.7436\n",
      "Epoch 37/150\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 0.3015 - accuracy: 0.8753 - val_loss: 0.6627 - val_accuracy: 0.7179\n",
      "Epoch 38/150\n",
      "37/37 [==============================] - 2s 45ms/step - loss: 0.2945 - accuracy: 0.8726 - val_loss: 0.6608 - val_accuracy: 0.7179\n",
      "Epoch 39/150\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 0.2904 - accuracy: 0.8781 - val_loss: 0.6564 - val_accuracy: 0.7244\n",
      "Epoch 40/150\n",
      "37/37 [==============================] - 2s 45ms/step - loss: 0.2842 - accuracy: 0.8864 - val_loss: 0.6630 - val_accuracy: 0.7179\n",
      "Epoch 41/150\n",
      "37/37 [==============================] - 2s 41ms/step - loss: 0.2773 - accuracy: 0.8864 - val_loss: 0.6657 - val_accuracy: 0.7051\n",
      "Epoch 42/150\n",
      "37/37 [==============================] - 1s 29ms/step - loss: 0.2735 - accuracy: 0.8947 - val_loss: 0.6689 - val_accuracy: 0.7115\n",
      "Epoch 43/150\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.2682 - accuracy: 0.8864 - val_loss: 0.6710 - val_accuracy: 0.7115\n",
      "Epoch 44/150\n",
      "37/37 [==============================] - 1s 13ms/step - loss: 0.2646 - accuracy: 0.8975 - val_loss: 0.6734 - val_accuracy: 0.7051\n",
      "Epoch 45/150\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.2587 - accuracy: 0.9058 - val_loss: 0.7036 - val_accuracy: 0.6859\n",
      "Epoch 46/150\n",
      "37/37 [==============================] - 2s 44ms/step - loss: 0.2552 - accuracy: 0.8947 - val_loss: 0.6955 - val_accuracy: 0.6923\n",
      "Epoch 47/150\n",
      "37/37 [==============================] - 1s 16ms/step - loss: 0.2507 - accuracy: 0.9030 - val_loss: 0.6973 - val_accuracy: 0.6923\n",
      "Epoch 48/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.2437 - accuracy: 0.9197 - val_loss: 0.6997 - val_accuracy: 0.6987\n",
      "Epoch 49/150\n",
      "37/37 [==============================] - 1s 26ms/step - loss: 0.2406 - accuracy: 0.9058 - val_loss: 0.6939 - val_accuracy: 0.7115\n",
      "Epoch 50/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.2348 - accuracy: 0.9141 - val_loss: 0.7031 - val_accuracy: 0.6987\n",
      "Epoch 51/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.2315 - accuracy: 0.9252 - val_loss: 0.7006 - val_accuracy: 0.6987\n",
      "Epoch 52/150\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.2279 - accuracy: 0.9169 - val_loss: 0.7019 - val_accuracy: 0.6987\n",
      "Epoch 53/150\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.2252 - accuracy: 0.9169 - val_loss: 0.7037 - val_accuracy: 0.7115\n",
      "Epoch 54/150\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.2214 - accuracy: 0.9252 - val_loss: 0.6988 - val_accuracy: 0.7051\n",
      "Epoch 55/150\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.2151 - accuracy: 0.9252 - val_loss: 0.7065 - val_accuracy: 0.7115\n",
      "Epoch 56/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.2173 - accuracy: 0.9307 - val_loss: 0.7157 - val_accuracy: 0.7051\n",
      "Epoch 57/150\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.2164 - accuracy: 0.9141 - val_loss: 0.7166 - val_accuracy: 0.7051\n",
      "Epoch 58/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 16ms/step - loss: 0.2077 - accuracy: 0.9224 - val_loss: 0.7084 - val_accuracy: 0.7115\n",
      "Epoch 59/150\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.2024 - accuracy: 0.9224 - val_loss: 0.7054 - val_accuracy: 0.7179\n",
      "Epoch 60/150\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.1974 - accuracy: 0.9280 - val_loss: 0.7003 - val_accuracy: 0.7115\n",
      "Epoch 61/150\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.1947 - accuracy: 0.9252 - val_loss: 0.6989 - val_accuracy: 0.7179\n",
      "Epoch 62/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.1932 - accuracy: 0.9280 - val_loss: 0.7091 - val_accuracy: 0.7244\n",
      "Epoch 63/150\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.1873 - accuracy: 0.9280 - val_loss: 0.6961 - val_accuracy: 0.7244\n",
      "Epoch 64/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.1847 - accuracy: 0.9363 - val_loss: 0.7030 - val_accuracy: 0.7244\n",
      "Epoch 65/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.1811 - accuracy: 0.9307 - val_loss: 0.6930 - val_accuracy: 0.7244\n",
      "Epoch 66/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.1815 - accuracy: 0.9363 - val_loss: 0.7260 - val_accuracy: 0.7179\n",
      "Epoch 67/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.1757 - accuracy: 0.9446 - val_loss: 0.7193 - val_accuracy: 0.7179\n",
      "Epoch 68/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.1715 - accuracy: 0.9446 - val_loss: 0.7112 - val_accuracy: 0.7179\n",
      "Epoch 69/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.1685 - accuracy: 0.9418 - val_loss: 0.7127 - val_accuracy: 0.7179\n",
      "Epoch 70/150\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.1669 - accuracy: 0.9446 - val_loss: 0.7167 - val_accuracy: 0.7179\n",
      "Epoch 71/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.1695 - accuracy: 0.9612 - val_loss: 0.7143 - val_accuracy: 0.7372\n",
      "Epoch 72/150\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.1609 - accuracy: 0.9474 - val_loss: 0.7034 - val_accuracy: 0.7372\n",
      "Epoch 73/150\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.1592 - accuracy: 0.9474 - val_loss: 0.7100 - val_accuracy: 0.7308\n",
      "Epoch 74/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.1521 - accuracy: 0.9501 - val_loss: 0.7007 - val_accuracy: 0.7308\n",
      "Epoch 75/150\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.1510 - accuracy: 0.9474 - val_loss: 0.7142 - val_accuracy: 0.7372\n",
      "Epoch 76/150\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.1504 - accuracy: 0.9529 - val_loss: 0.7130 - val_accuracy: 0.7372\n",
      "Epoch 77/150\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.1491 - accuracy: 0.9446 - val_loss: 0.7013 - val_accuracy: 0.7500\n",
      "Epoch 78/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.1436 - accuracy: 0.9557 - val_loss: 0.7106 - val_accuracy: 0.7372\n",
      "Epoch 79/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.1434 - accuracy: 0.9529 - val_loss: 0.7191 - val_accuracy: 0.7372\n",
      "Epoch 80/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.1382 - accuracy: 0.9529 - val_loss: 0.7082 - val_accuracy: 0.7500\n",
      "Epoch 81/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.1358 - accuracy: 0.9584 - val_loss: 0.7116 - val_accuracy: 0.7500\n",
      "Epoch 82/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.1318 - accuracy: 0.9584 - val_loss: 0.7058 - val_accuracy: 0.7500\n",
      "Epoch 83/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.1307 - accuracy: 0.9529 - val_loss: 0.7052 - val_accuracy: 0.7500\n",
      "Epoch 84/150\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.1308 - accuracy: 0.9557 - val_loss: 0.7120 - val_accuracy: 0.7564\n",
      "Epoch 85/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.1266 - accuracy: 0.9474 - val_loss: 0.7067 - val_accuracy: 0.7564\n",
      "Epoch 86/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.1300 - accuracy: 0.9474 - val_loss: 0.7072 - val_accuracy: 0.7500\n",
      "Epoch 87/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.1229 - accuracy: 0.9584 - val_loss: 0.6971 - val_accuracy: 0.7564\n",
      "Epoch 88/150\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.1196 - accuracy: 0.9529 - val_loss: 0.6978 - val_accuracy: 0.7564\n",
      "Epoch 89/150\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 0.1212 - accuracy: 0.9446 - val_loss: 0.7071 - val_accuracy: 0.7500\n",
      "Epoch 90/150\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 0.1233 - accuracy: 0.9584 - val_loss: 0.7431 - val_accuracy: 0.7436\n",
      "Epoch 91/150\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.1238 - accuracy: 0.9501 - val_loss: 0.7071 - val_accuracy: 0.7500\n",
      "Epoch 92/150\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.1150 - accuracy: 0.9668 - val_loss: 0.7121 - val_accuracy: 0.7628\n",
      "Epoch 93/150\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.1092 - accuracy: 0.9668 - val_loss: 0.7213 - val_accuracy: 0.7500\n",
      "Epoch 94/150\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.1076 - accuracy: 0.9668 - val_loss: 0.7159 - val_accuracy: 0.7628\n",
      "Epoch 95/150\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 0.1061 - accuracy: 0.9695 - val_loss: 0.7210 - val_accuracy: 0.7564\n",
      "Epoch 96/150\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 0.1025 - accuracy: 0.9695 - val_loss: 0.7277 - val_accuracy: 0.7564\n",
      "Epoch 97/150\n",
      "37/37 [==============================] - 1s 30ms/step - loss: 0.1042 - accuracy: 0.9640 - val_loss: 0.7295 - val_accuracy: 0.7564\n",
      "Epoch 98/150\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 0.0974 - accuracy: 0.9778 - val_loss: 0.7313 - val_accuracy: 0.7500\n",
      "Epoch 99/150\n",
      "37/37 [==============================] - 1s 21ms/step - loss: 0.0953 - accuracy: 0.9834 - val_loss: 0.7437 - val_accuracy: 0.7436\n",
      "Epoch 100/150\n",
      "37/37 [==============================] - 1s 15ms/step - loss: 0.0941 - accuracy: 0.9723 - val_loss: 0.7513 - val_accuracy: 0.7436\n",
      "Epoch 101/150\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0937 - accuracy: 0.9806 - val_loss: 0.7417 - val_accuracy: 0.7500\n",
      "Epoch 102/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.1239 - accuracy: 0.9612 - val_loss: 0.7157 - val_accuracy: 0.7821\n",
      "Epoch 103/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0915 - accuracy: 0.9751 - val_loss: 0.7381 - val_accuracy: 0.7500\n",
      "Epoch 104/150\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.1000 - accuracy: 0.9751 - val_loss: 0.7398 - val_accuracy: 0.7500\n",
      "Epoch 105/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0920 - accuracy: 0.9778 - val_loss: 0.7459 - val_accuracy: 0.7500\n",
      "Epoch 106/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0848 - accuracy: 0.9778 - val_loss: 0.7421 - val_accuracy: 0.7564\n",
      "Epoch 107/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0846 - accuracy: 0.9806 - val_loss: 0.7535 - val_accuracy: 0.7500\n",
      "Epoch 108/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0802 - accuracy: 0.9806 - val_loss: 0.7489 - val_accuracy: 0.7500\n",
      "Epoch 109/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0808 - accuracy: 0.9834 - val_loss: 0.7534 - val_accuracy: 0.7500\n",
      "Epoch 110/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0794 - accuracy: 0.9806 - val_loss: 0.7593 - val_accuracy: 0.7500\n",
      "Epoch 111/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0776 - accuracy: 0.9834 - val_loss: 0.7649 - val_accuracy: 0.7500\n",
      "Epoch 112/150\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0760 - accuracy: 0.9806 - val_loss: 0.7602 - val_accuracy: 0.7500\n",
      "Epoch 113/150\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0719 - accuracy: 0.9834 - val_loss: 0.7638 - val_accuracy: 0.7564\n",
      "Epoch 114/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0724 - accuracy: 0.9861 - val_loss: 0.7597 - val_accuracy: 0.7500\n",
      "Epoch 115/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0702 - accuracy: 0.9834 - val_loss: 0.7678 - val_accuracy: 0.7436\n",
      "Epoch 116/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0696 - accuracy: 0.9834 - val_loss: 0.7718 - val_accuracy: 0.7436\n",
      "Epoch 117/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0694 - accuracy: 0.9861 - val_loss: 0.7674 - val_accuracy: 0.7436\n",
      "Epoch 118/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0663 - accuracy: 0.9861 - val_loss: 0.7624 - val_accuracy: 0.7692\n",
      "Epoch 119/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0662 - accuracy: 0.9861 - val_loss: 0.7678 - val_accuracy: 0.7628\n",
      "Epoch 120/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0635 - accuracy: 0.9861 - val_loss: 0.7664 - val_accuracy: 0.7628\n",
      "Epoch 121/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0625 - accuracy: 0.9889 - val_loss: 0.7696 - val_accuracy: 0.7628\n",
      "Epoch 122/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0634 - accuracy: 0.9834 - val_loss: 0.7782 - val_accuracy: 0.7821\n",
      "Epoch 123/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0737 - accuracy: 0.9834 - val_loss: 0.7927 - val_accuracy: 0.7500\n",
      "Epoch 124/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0635 - accuracy: 0.9834 - val_loss: 0.7909 - val_accuracy: 0.7692\n",
      "Epoch 125/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0631 - accuracy: 0.9834 - val_loss: 0.7920 - val_accuracy: 0.7628\n",
      "Epoch 126/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0614 - accuracy: 0.9889 - val_loss: 0.7903 - val_accuracy: 0.7692\n",
      "Epoch 127/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0579 - accuracy: 0.9861 - val_loss: 0.7954 - val_accuracy: 0.7692\n",
      "Epoch 128/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0578 - accuracy: 0.9806 - val_loss: 0.7917 - val_accuracy: 0.7821\n",
      "Epoch 129/150\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0567 - accuracy: 0.9861 - val_loss: 0.7968 - val_accuracy: 0.7885\n",
      "Epoch 130/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0549 - accuracy: 0.9889 - val_loss: 0.8028 - val_accuracy: 0.7821\n",
      "Epoch 131/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0522 - accuracy: 0.9861 - val_loss: 0.8068 - val_accuracy: 0.7756\n",
      "Epoch 132/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0509 - accuracy: 0.9917 - val_loss: 0.8029 - val_accuracy: 0.7885\n",
      "Epoch 133/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0504 - accuracy: 0.9945 - val_loss: 0.8080 - val_accuracy: 0.7885\n",
      "Epoch 134/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0499 - accuracy: 0.9861 - val_loss: 0.8149 - val_accuracy: 0.7756\n",
      "Epoch 135/150\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.0505 - accuracy: 0.9945 - val_loss: 0.8107 - val_accuracy: 0.7949\n",
      "Epoch 136/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0578 - accuracy: 0.9834 - val_loss: 0.8291 - val_accuracy: 0.7885\n",
      "Epoch 137/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0512 - accuracy: 0.9945 - val_loss: 0.8343 - val_accuracy: 0.7949\n",
      "Epoch 138/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0472 - accuracy: 0.9889 - val_loss: 0.8301 - val_accuracy: 0.7949\n",
      "Epoch 139/150\n",
      "37/37 [==============================] - 0s 9ms/step - loss: 0.0461 - accuracy: 0.9945 - val_loss: 0.8320 - val_accuracy: 0.7949\n",
      "Epoch 140/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0458 - accuracy: 0.9861 - val_loss: 0.8389 - val_accuracy: 0.7756\n",
      "Epoch 141/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0465 - accuracy: 0.9917 - val_loss: 0.8355 - val_accuracy: 0.7949\n",
      "Epoch 142/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0449 - accuracy: 0.9945 - val_loss: 0.8416 - val_accuracy: 0.7949\n",
      "Epoch 143/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0439 - accuracy: 0.9945 - val_loss: 0.8471 - val_accuracy: 0.7821\n",
      "Epoch 144/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0428 - accuracy: 0.9972 - val_loss: 0.8493 - val_accuracy: 0.8013\n",
      "Epoch 145/150\n",
      "37/37 [==============================] - 0s 12ms/step - loss: 0.0423 - accuracy: 0.9917 - val_loss: 0.8610 - val_accuracy: 0.8141\n",
      "Epoch 146/150\n",
      "37/37 [==============================] - 0s 11ms/step - loss: 0.0419 - accuracy: 0.9917 - val_loss: 0.8580 - val_accuracy: 0.7885\n",
      "Epoch 147/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0410 - accuracy: 0.9917 - val_loss: 0.8562 - val_accuracy: 0.8205\n",
      "Epoch 148/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0408 - accuracy: 0.9945 - val_loss: 0.8627 - val_accuracy: 0.8141\n",
      "Epoch 149/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0444 - accuracy: 0.9917 - val_loss: 0.8827 - val_accuracy: 0.8077\n",
      "Epoch 150/150\n",
      "37/37 [==============================] - 0s 10ms/step - loss: 0.0400 - accuracy: 0.9917 - val_loss: 0.8666 - val_accuracy: 0.8013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20bf8631ee0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, validation_split=0.3, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fc0bf922",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T15:03:04.032538Z",
     "start_time": "2022-04-29T15:03:03.725460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2871 - accuracy: 0.9381\n",
      "accuracy: 93.81%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd3fe66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
